id,body,subject,category,action
194e90265a3c53fe,"*지속가능원이 추천하는 2025-1 지속가능 교과목 25선!*

ESG? 지속가능성? SDGs? 생물다양성?
남들이 이야기할 때 긴가민가 알아듣지 못해 난감했던 경험이 있으셨던 분!
혹은 강의를 통해 지속가능성을 더욱 깊이 알아보고 싶으셨던 분!

여러분들을 위해 지속가능원이 <2025학년도 1학기 지속가능 교과목>을 준비했습니다.
여러분들의 시간표 사이사이 지속가능 교과목 하나 쏙 넣어보시면 어떨까요? :)

다음 지속가능원 링크를 통해 더 자세히 알아볼 수 있답니다 ▶ *게시물 링크 바로가기*

",[지속가능원] 지속가능원이 추천하는 2025-1 지속가능 교과목 25선!,other,read only
194e343333e5ff27,"












",ICT명품인재양성사업단 뉴스레터 겨울호를 보내 드립니다.,academic,read only
194e34039181a3c0,"안녕하세요,


2024년 업적평가를 위해 실적 업데이트 요청을 드립니다. 이전에 입력한 실적 중에도 누락된 실적이 있는지 확인하시고, 2024년
실적의 경우 추가 업데이트 해주시면 됩니다.

논문의 경우

https://koreauniv.pure.elsevier.com/en/organisations/department-of-chemical-and-biological-engineering
 혹은



https://www.scopus.com/search/form.uri?zone=TopNavBar&origin=AuthorProfile&display=basic#author
에서
저자로 검색하시면  누락된 논문이 확인가능할 것입니다.


첨부해드리는 파일을 활용해주시고, 이전 실적은 임의로 삭제하지 말아주십시오.

환산편수의 경우, 수식이 걸려 있기 때문에 삭제 하지 말아주십시오.

증빙은 출력하셔서 제출 부탁드립니다.


- 실적기간: 2024.1.~2024.12.

- 제출일: 2월 7일 (금) * 교수님께 누락된 실적이 있는지 꼭 확인하고 제출하십시오!

- 실적작성 방법:

  1. 논문=> 위의 실적 기간내오프라인 출판 완료된 논문작성 (증빙 제출 필요 없음)

        * 대학원생 논문의 경우: 첨부한 파일에 이름이 있는 학생이 저자로, 네부캠대학교 정보학과 저자로 들어간 학생의 경우
작성함. BK미참여 연구실의 경우 2020년 2학기 이후 재학생 논문이 해당됨.

                                          BK 연구교수가 있는 경우 신진연구인력 시트에 BK연구 교수
실적도 작성해야 함. 임용된 이후 실적 모두 포함. 단, 소속이 네부캠대 정보학과이어야 함)

                                          환산편수까지 작성, 공동연구 구분 까지 작성 (피인용,
IF. 상위 %, IF보정값, ES보정값은 연구단에서 일괄 입력 예정임.)

                                           IF, ES, 분야별 상위%는 JCR 2023값을 파일로
전달하오니,  참고자료로 활용하십시오. 값은 넣지 않으셔도 됩니다..

   2. 학회=>  위의 실적 기간내 수상실적만 작성, 2024년 학회 참석시 참여대학원생 이어야 함.

                   2024년 8월까지 학회-2024년 1학기 참여대학원생 명단 확인, 2025년 2월까지 학회-
2024년 2학기 참여대학원생 명단 확인

   3. 특허=>  위의 실적 기간내 국내, 해외 모두 등록 실적만 작성

   4. 연구비=> 위의 실적 기간내 입금된 실적만 입력 , 실시간계좌이체 과제의 경우 해당사이트 실적을 작성할 것 (RCMS 등):
방법을 모르면 전임 방장 혹은 저에게 문의해주십시오.



- 증빙:  학술대회 (학회초록첫표지(학회제목, 일정, 장소 확인가능한면), 본인발표한면, 상장)

           연구비 (본교관리 연구비- 연구계약자료, 타교관리연구비-협약서, 공동연구비의 경우 (본교,타교 모두)- 지분확인서)

           특허 (특허등록증)

           기술이전 (계약서, 입금증, 발명보상금지급동의서)

           국제화 (적은 내용을 증빙할 수 있는 증빙. 해외공동논문, MOU증빙, 공동과제계약서, 단순교류인경우 E-MAIL,
장기연수의 경우 초청장 등...)

           교육역량실적 (저서 표지, 상장, 온라인 강의의 경우 인터넷 주소 등)

           산업사회기여실적(세미나, 자문 일정확인가능한 메일 & PPT파일 앞면, 산업체이나 교육실적의 경우 내용이 확인되는
증빙)

 - 실적입력방법 확인하고 작성할 것.
",2024년 업적평가를 위한 연구실적 업데이트 요청의 건 (~2월 7일),academic,action needed
194e334940f6bad0,"안녕하세요
친환경 디지털 정보과학 교육연구단 함이열입니다.

BK21 대학원혁신사업 2025년 1학기 대학원 맞춤형 연구역량 프로그램 - *영어논문작성법* 워크숍을 안내드립니다.

해당 워크숍은 정보학과 학생만 대상으로 진행되니 많은 참여 부탁드립니다.
*(BK21사업 참여대학원생들은 참석 여부 확인 예정, 신입생 필수 참석, 연구실 별 4명 이상 필수 참석)*
연구실 내 참석 신청자 명단을 취합하여 *2월 5일(수)까지* 회신 부탁드립니다.

*[정보학과 공학계열 영어논문 작성법]*

  - 일   시: 2025. 2. 7.(금) 14시~16시
  - 대   상: 정보학과 대학원생 40명
  - 장   소: 111동 111호
  - 강연자: 나천재 박사님(발표 대박스 대표)
  - 강의개요:
1. 논문작성 과정 및 순서 (고수/초보 저자 비교)
2. 논문 섹션별 유의 사항 및 영어 관련 팁
3. 중요한 정보를 효과적으로 부각시키는 방법
4. 자주 보이는 영어 글쓰기 스타일 관련 오류
5. 다양한 AI도구 활용 방법 및 유의할 점

감사합니다.

*함이열* Ham Eyeol
친환경 디지털 정보과학 교육연구단
",[BK] 2025년 2월 7일(금) BK21 대학원혁신사업 영어논문작성법 워크숍 안내 (신청자 명단 제출 ~금일 까지),academic,action needed
194e325d62686180,"Hi there,

We charged $5.20 to your credit card ending in 2043 to fund your OpenAI API
credit balance.

You may review your billing history

at
any time.

You received this email because you have a paid account with OpenAI
Organization: Personal (org-JMJcjhcxu4XbkPBvkQYeUO6q)
",Your OpenAI API account has been funded,other,read only
194e3256f9b4e6b8,"Hi there,

We charged $5.51 to your credit card ending in 2043 to fund your OpenAI API
credit balance.

You may review your billing history

at
any time.

You received this email because you have a paid account with OpenAI
Organization: Personal (org-JMJcjhcxu4XbkPBvkQYeUO6q)
",Your OpenAI API account has been funded,other,read only
194e324bf6649106,"Hi there,

We charged $5.34 to your credit card ending in 2043 to fund your OpenAI API
credit balance.

You may review your billing history

at
any time.

You received this email because you have a paid account with OpenAI
Organization: Personal (org-JMJcjhcxu4XbkPBvkQYeUO6q)
",Your OpenAI API account has been funded,other,read only
194e31fb01860163,"[image: icon]
일어나 스터디해야지
일어나 스터디해야지에 새 업데이트
내 워크스페이스에서 6페이지의 변경 사항을 검토합니다.
[image: icon] 강감찬 정리


GC K님이 이 페이지 페이지를 편집했습니다.


Abstract

LLaMa-1은 7B ~ 65B이며 공개된 데이터셋으로만 학습했다.

13B에서 GPT-3 175B 제쳤다.

65B는 다른 SOTA 모델과 비빌 수 있다.

모델 공개했다.

1. Introduction

2. Approach

2.1 Pre-training Data

English CommonCrawl [67%]

C4 [15%]

Github [4.5%]

Wikipedia [4.5%]

Gutenberg and Book3 [4.5%]

ArXiv [2.5%]

Stack Exchange [2%]

Tokenizer

2.2 Architecture

Pre-normalization [GPT3]

SwiGLU activation function [PaLM]

Rotary Embedding [GPTNeo]

2.3 Optimizer

2.4 Efficient implementation

3. Main results

3.1 Common Sense Reasoning

3.2 Closed-book Question Answering

3.3 Reading Comprehension

3.4 Mathematical reasoning

3.5 Code generation

3.6 Massive Multitask Language Understanding

3.7 Evolution of performance during training

4. Instruction Finetuning

5. Bias, Toxicity and Misinformation

5.1 RealToxicityPrompts

5.2 CrowS-Pairs

5.3 WinoGender

5.4 TruthfulQA

6. Carbon footprint

7. Related work

Language models

Architecture

Scailing

8. Conclusion

LLM에서 어느 정도 크기가 되면 few-shot 속성을 가진다.

모델 크기보다는 데이터가 많은 게 좋음 (Hoffmann et al. 2022)

Objective 성능에 도달하기 좋은 모델은 추론이 빠른 모델이다.

[image: icon] Language Models are Few-Shot Learner


GC K님이 이 페이지 페이지를 편집했습니다.


Venue
OpenAI
Property
Transformer
Transformer
decoder

C
유채은님이 이 페이지 페이지를 편집했습니다.


첨부 파일
https://prod-files-secure.s3.us-west-2.amazonaws.com/f9704662-acf5-46ed-a1ca-9ab0f17e8167/e5e79006-72b2-4df7-9c0c-3ac7c82e263d/Language_Models_are_Few-Shot_Learners.pdf
Property
Transformer

[image: icon] Exploring the Limits of Transfer Learning with a Unified
Text-to-Text Transformer


GC K님이 이 페이지 페이지를 편집했습니다.


Property
Transformer
Transformer
encoder
decoder

[image: icon] Language Models are Unsupervised Multitask Learners


GC K님이 이 페이지 페이지를 편집했습니다.


Property
Transformer
Transformer
decoder

[image: icon] Improving Language Understanding by Generative Pre-Training


GC K님이 이 페이지 페이지를 편집했습니다.


Property
Transformer
Transformer
decoder

[image: icon] BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding


GC K님이 이 페이지 페이지를 편집했습니다.


Property
Transformer
Transformer
encoder

Notion
문서, 프로젝트, 위키를 위한
커넥티드 워크스페이스 Notion.so

이메일 설정 업데이트

",일어나 스터디해야지에서 GC K 님 외 1명이 업데이트했습니다,other,read only
194e31dc5c94b84b,"[image: icon]
일어나 스터디해야지
일어나 스터디해야지에 새 업데이트
내 워크스페이스에서 1페이지의 변경 사항을 검토합니다.
[image: icon] 안혜준 정리


혜준 안님이 이 페이지 페이지를 편집했습니다.


이미지
image.png
비어 있음

혜준 안님이 이 페이지 페이지를 편집했습니다.



   - repetitive text, world modeling failure, unnatural topic switching 같은
   건 존재하긴함


앞서 말했듯이 제로샷 설정으로 사전학습 모델 그대로 써도 성능이 좋다!


   - 언어 모델링 관련된 task들에서는 SOTA 달성



   - 하지만 prompting으로 잘만하면 어느정도 성능이 나온다!(놀라워)



   - Question Answering, Reading Comprehension, summarization, translation
   등에는 zero shot 설정으론 SOTA는 힘들었


혜준 안님이 이 페이지 페이지를 편집했습니다.


GPT(2018.06) → BERT(2018.10) → GPT2(2019.02) 4개월 단위로 자신들의 모델이 SOTA를 달성하였다며
논문이 발표되었다.


   - task specific training 없이 SOTA 달성



   - 40GB 인터넷 text에서 훈련됨



   - 이번엔 훈련된 모델을 공개하지 않겠음(호들갑)



   - 대신 연구 목적으로 124M 파라미터의 작은 모델 공개 해드림



   - 근데 결국 전부 공개함



   - 1.5B 파라미터의 GPT-2 XL



   - 2019년 8월: 355M 출시



   - 2019년 11월: 1.5B 최종 GPT-2-XL 출시



   - 파라미터 비교



   - BERT: 340M



   - GPT-1: 117M



   - GPT-2: 1.5B



   - GPT-1에 비해 10배 이상의 파라미터 + 10배이상의 데이터로 학습함



   - 별도 도메인별 학습 세트 안써도 그냥 뛰어남



   - 다양한 NLP 작업에서 별도 작업별 trainset 쓰지 않아도 알아서 학습하기 시작



   - 물론 SOTA는 안되지만 비지도 학습만으로도 성능이 나온다는 걸 시사


입력 → 합성 텍스트 샘플 생성


   - 인간 품질에 유사하게 생성되며, 한 페이지 이상의 텍스트에 걸쳐 일관성을 보여준다



   - repettive text, world modeling failure, unnatural topic switching 같은 건
   존재하긴함



   - 이건 현재(2024년)의 모델들에도 고질적으로 왕왕 일어나는 문제!


Notion
문서, 프로젝트, 위키를 위한
커넥티드 워크스페이스 Notion.so

이메일 설정 업데이트

",일어나 스터디해야지에서 혜준 안이 업데이트했습니다,other,read only
194e31d468c2ecad,"[image: icon]
일어나 스터디해야지
일어나 스터디해야지에 새 업데이트
내 워크스페이스에서 4페이지의 변경 사항을 검토합니다.
[image: icon] 유채은 정리


C
유채은님이 이 페이지 페이지를 편집했습니다.


WebText의 training set과 특정 evaluation dataset간의 data overlap은 evaluation
result에 작지만 일관된 이점을 가져다줌

근데 이 overlap은 supervised dataset에서 overlap비율보다 낮음

그러니까 괜찮지?

또 아직 train 성능 오를 때마다 test 성능 오름

아직 train 단물 덜 빨아 먹었는데 이정도임

삭제됨
Related Work
삭제됨
Conclusion
unsupervised training은 유망하다

사전 훈련이 잘 먹힌 이유와 같음

독해에서 GPT-2의 제로샷 성능 뛰어남

근데 요약같은 다른 작업들은 아직 좀 떨어짐

언어 모델은 충분한 용량을 가질 때에 성능 발휘 시작함

Discussion & Conclusion

C
유채은님이 이 페이지 페이지를 편집했습니다.


Abstract

Introduction

Approach

Experiments

Generalization vs Memorization

Related Work

Discussion

Conclusion

supervision에서의 탈피

성능 향상에는 모델의 capacity가 중요

아직 WebText에 underfitting(미래가 밝다)

현재:

큰 모델

supervised largedata

⇒ narrow experts

현재의 문제점: data 분포 변화에 취약

우리는 generalist를 만들거임

하나의 task가 아니라, 다양한 task에 대해 training 해야함

supervised data가 아예 없거나 극소수일 때, 특정한 task들을 수행하기 위한 language model

문장들은 단어들로 구성되어 있음

각 단어가 등장할 확률이 최대화

P(output|input,task)

어떤 문제를 푸는 지(tastk)까지도 조건으로 주어져야함

unsupervised objective의 전역 최솟값과 supervised objective이 같다

단, unsupervised objective의 convergence가 문제가 되곤 한다.

Common Crawl dataset에서 휴리스틱한 부분 제외

Wiki는 문제로 많이 쓰여서 치팅이 될 수 있으니 삭제

character category가 다르면 merge하지 않게끔 하여 해결 (abc | ,.?!)

Input representation

Training Dataset

Model

layer normalization이 각 sub-block의 input 부분으로 이동

추가적인 layer normalization이 마지막 self-attention block에 적용됨

이어서 model의 깊이에 따라 residual path의 누적에 관한 initialization이 변경됨 Residual layer의
weight에 1/√N을 곱해주면서 scaling한다.

GPT1에 비해 vocabulary size가 50,257로 증가

batch는 512로 증가

context vector의 크기도 512에서 1024로 증가

Language Modeling

small dataset에서 성능 향상

long-term dependency dataset에서 성능 향상

Children's Book Test

LAMBADA

잘하네요

LM의 long-range dependency를 측정하기 위해 고안된 dataset

잘하네요

품사에 따른 LM 성능 측정 dataset

마지막 단어가 마무리가 잘 안 됨 → 불용어 필터 걸었더니 또 오름

Winograd Schema Challenge

model이 text 속에서 모호함을 얼마나 잘 해결할 수 있는지 측정하는 commonsense reasoning

겁나 잘

train dataset 내부에 test dataset이랑 겹치는 부분이 있으면 성능 평가가 신뢰성 있지 않음

일반화 성능이 과대해석됨

[image: icon] 이채호 정리


채호 이님이 이 페이지 페이지를 편집했습니다.


bloom filter

중복된 데이터 web text와 eval dataset에 있으면 성능향상이있다.

Related Work

GloVe

Discussion

GPT-2 제로샷일때는 사용하기 어렵다

채호 이님이 이 페이지 페이지를 편집했습니다.


파라미터나 아키텍쳐 수정없이 제로샷에서 성능이 많이 뽑힌좋다.

채호 이님이 이 페이지 페이지를 편집했습니다.


Generalization vs Memorization

Summarization, translation, question answering 등도 테스트함

채호 이님이 이 페이지 페이지를 편집했습니다.


Training dataset

데이터셋 최대한 넓고 다양하게 만들어야한다.

common crawl은 퀄리티 이슈있다. 그래서 큐레이팅함 (레딧에서 3 karma 이상 된것들) → WebText (45
million links)

Input representation

BPE charcter and word level language modeling

Model

트랜스포머 씀

Experiments

log-probability 로 dataset 의 퀄리티를 평가했다.

Children’s book test

Adding a stop word filter

Winograd Schema chllenge → commonsense reasoning (애매한 텍스트들)

THe conversation question asnwering dataset (CoQA)

채호 이님이 이 페이지 페이지를 편집했습니다.


파라미터나 아키텍쳐 수정없이 제로샷에서 성능이 많이 뽑힌다.

Approach

input 만 아니라 task 에도 conditioning이 돼야한다.

2 추가 업데이트

[image: icon] Language Models are Unsupervised Multitask Learners


GC K님이 이 페이지 페이지를 편집했습니다.


첨부 파일
https://prod-files-secure.s3.us-west-2.amazonaws.com/f9704662-acf5-46ed-a1ca-9ab0f17e8167/cc42318f-12c7-4685-94dd-7321de3b22bc/GPT-2.pdf

GC K님이 이 페이지 페이지를 편집했습니다.


토큰화/전처리 결함을 최대한 많이 제거하여 복원 가능한 디토크나이저를 사용

Penn Treebank, WikiText-2와 같이 학습 토큰이 1~2백만 개에 불과한 작은 데이터셋에서 큰 성능 향상이 관찰

장기 의존성 측정을 위한 LAMBADA, Children’s Book Text와 같은 데이터셋에서도 큰 성능 향상이 관찰

One Billion Word Benchmark에서 이전 연구보다 성능이 크게 떨어짐 → 데이터셋 크기가 가장 큼, 전처리 과정 때문일
가능성 높음 → 1BW의 문장 단위 셔플링이 장기 구조 제거

PTBenn Treebank 스타일 토큰화 결함 제거(문장 기호와 단어 분리)를 위해 디토크나이저 적용

CBT: 언어 모델을 다양한 단어 범주에서 평가하기 위해 만들어진 데이터셋

장기 의존성 모델링 테스트

최소 50개 토큰이 필요한 문장의 마지막 단어 예측하는 작업

퍼플렉시티를 평가 지표로 사용하는 대신, 생략된 단어에 대해 10개 선택지 중 정답을 예측하는 정확도를 보고

⇒ 언어 모델이 단어가 문장의 마지막이어야 한다는 제약을 사용하지 않음

CoQA: 7개 서로 다른 도메인의 문서와, 이 문서를 기반으로 질문자와 응답자 간의 대화로 구성

GPT-2는 지도 학습 없이도 괜찮음, ‘who’ 질문에 문서에서 이름을 선택하는 검색 기반 휴리스틱을 자주 사용하는 것으로 보임

생성된 요약은 질적으로 요약과 유사, 기사에서 최근 내용에 집중하거나 구체적인 세부 사항을 혼동하는 경우가 자주 발생

WebText 바이트 수준 언어 감지기 → 프랑스어 데이터는 10MB → 이전 비지도 학습 번역 연구에서 사용된 프랑스어 코퍼스보다
500배 작음

언어 모델의 문맥은 질문-답변 예제로 초기화 → 데이터셋의 짧은 답변 스타일을 모델이 추론하도록 돕습니다.도움

언어 모델이 포함하고 있는 정보 테스트: 사실 기반 질문 → 얼마나 자주 정답을 생성하는지 평가

테스트 데이터가 훈련 데이터에 얼마나 포함됐는지 분석하는게 중요!

이를 위해서 우리는 WebText 훈련 데이터셋 토큰의 8-그램 블룸 필터 생성

일반적인 언어 모델 데이터셋의 테스트 셋은 WebText 훈련 데이터와 1~6% 중복을 가짐 → 평균 중복률은 3.2%

많은 데이터셋은 자신들의 훈련 셋과 더 큰 중복 → 평균 중복률 5.9%

→ WebText는 특별이 중복 문제가 많은 데이터셋은 아님

n-그램 중복 기반 중복 제거를 NLP 데이터셋의 훈련-테스트 분할 생성 시 사용 권장함

이 연구: 대규모 언어 모델의 성능을 측정하는데 초점

언어 작업을 위한 사전 훈련 방법에 대한 광범위한 연구가 진행됨

최근 연구에서 대화 생성 및 질문 응답과 같은 어려운 생성에서도 언어 모델 사전 훈련이 유용하다는 것을 보여줌

우리의 결과: 비지도 작업 학습이 탐구할 만한 유망한 추가 연구 영역임을 시사

실질적인 응용 측면에서는 GPT-2의 제로샷 성능은 여전히 실용적이라고 보기 어려움

QA나 번역과 같은 본 연구에서 평가한 일반 작업에서도, 언어 모델이 충분히 클 때서야 비로소 단순한 기준을 능가하기 시작

GPT-2 제로샷이 잠재력 있으나, fine-tuning으로 달성할 수 있는 최대 성능은 명확하지 않음

GPT-2의 추가 훈련 데이터와 모델 용량이 BERT가 보여준 단방향 표현의 비효율성을 극복할 수 있을지는 미지수

GC K님이 이 페이지 페이지를 편집했습니다.


예비 실험에서 multitask learning 할 수 있었지만, 학습 속도는 더 느렸음

지도 학습의 목적 함수 == 비지도 학습 목적 함수 → 시퀀스 일부에서만 평가되므로 비지도 학습 목적 함수의 global minimun
== 지도 학습 목적 함수의 global minimum

연구진은 충분한 capacity용량을 가진 언어 모델이 작업 추론 및 수행을 학습할 것이라 추측 → 데이터 수집 방식과 무관한 예측 → 사실상
비지도 multitask learning 수행

사람에 의해 큐레이션, 필터링된 웹 페이지만 스크래핑함

→ WebText

위키피디아 문서는 다른 데이터셋에서 흔히 사용하므로 제외 → 훈련과 평가에서 데이터 중복으로 분석이 복잡해질 가능성 방지

Gillick et al. (2015): 유니코드 문자열을 UTF-8 바이트 시퀀스로 처리하면 이런 요구 사항을 충족할 수 있음 →
현재 바이트 수준 언어 모델은 One Billion Word Benchmark와 같은 대규모 데이터셋에서 단어 수준 언어 모델에 비해 안
좋음

이를 방지하기 위해 BPE가 바이트 시퀀스의 문자 카테고리를 넘어서 병합하지 못하도록 함.(기호는 병합 X) → 공백은 허용하여 단어를
여러 토큰으로 분리하는 단점 최소화하며 압축 효율을 크게 향상

이러한 입력 표현 방식: 단어 수준 언어 모델의 효율성 + 바이트 수준 접근법의 범용성

모든 유니코드 문자열에 확률 할당 가능하므로 전처리, 토큰화, 어휘 크기와 관계 없이 어떤 데이터셋에서도 언어 모델 평가 가능

Layer Norm이 각 서브 블록의 입력으로 이동: pre-activation residual network과 유사, 최종 셀프
어텐션 블록 뒤에 Layer Norm 추가

가장 큰 모델인 GPT-2는 GPT보다 한 자리수 이상 더 많은 파라미터

가장 작은 모델은 기존 GPT와 동일, 두 번째로 작은 모델은 BERT Large와 동일

제로샷 작업 전이를 위해 WebText 언어 모델이 학습된 모델링 구조에서 어떻게 제로샷 도메인으로 전이를 하는지 설명

토큰화/전처리 결함을 최대한 많이 제거하여 복원 가능한 디토크나이저를 사용

GC K님이 이 페이지 페이지를 편집했습니다.


현재 NLP에서 가장 뛰어난 성능 → pre-training + supervised fine-tuning → 더 유연한 전이 학습 형태로
발전

하지만 일반적인 시스템 → 동일한 입력에 대해 여러 작업을 수행할 수 있어야 함! → 작업에도 조건을 걸어야 함

GC K님이 이 페이지 페이지를 편집했습니다.


WebText라는 수백만 개 웹페이지로 구성된 데이터셋으로 훈련 → 지도 없이도 NLP 특정 작업 학습

언어 모델의 용량은 zero-shot 작업 전이에서 핵심임. 용량 늘리면 작업 성능이 로그-선형 방식으로 향상됨.

GPT-2: 15억개 파라미터 트랜스포머 모델 → 8개 언어 모델링 데이터셋 중 7개에서 제로샷 설정으로 SOTA. WebText에
대해 여전히 underfit

GPT-2 모델이 과거의 언어 모델보다 더 자연스럽고 논리적인 텍스트를 생성할 수 있게 됨. 질문이나 주어진 문맥에 따라 적절하고
일관된 텍스트를 만들어내는 능력이 향상됨. 이전 모델은 엉뚱한 문장을 생성하거나 문장이 서로 연결되지 않아 어색한 경우가 많았음.

연구진의 목표: 각 작업마다 훈련 데이터셋을 수동으로 만들고 라벨링할 필요가 없게 되는 것 → 일반적인 시스템

Multitask Learning은 일반적인 성능을 향상하는 프레임워크임 → NLP에서는 아직 초기 단계

→ multitask learning을 위한 추가 설정을 탐구할 동기

12 추가 업데이트

[image: icon] 안혜준 정리


혜준 안님이 이 페이지 페이지를 편집했습니다.



   - 하지만, 요약 같은 다른 작업은 아직 초보적인 성능임



   - 그렇더라도 충분한 파라미터가 보장되면 다양한 작업에서 랜덤 결과보다 높아지기 시작하는 경향을 확인



   - GPT-2의 학습 데이터와 용량은 BERT가 이야기한 단방향 표현의 비효율성을 극복하기 충분


혜준 안님이 이 페이지 페이지를 편집했습니다.



   - GPT 2는 reading comprehension에서 zero shot설정으로도 강점을 보인다.



   - 하지만,


혜준 안님이 이 페이지 페이지를 편집했습니다.



   - squad도 예시 few shot 넣어준Qeustion Answering도 예시 few shot 넣어준다 이때 4.1%의
   정답률을 보였다



   - 가장 확신하는 1%에 대해서는 63.1%의 정답률을 보여줬다.



   - 물론 Open domain Quesiton answering은 30 ~ 50%가 나오기 떄문에 이와 비교하면 성능이 많이
   낮지만, 그래도 비지도 학습만으로 이런 것도 풀수 가 있다는 걸 시사한다.


혜준 안님이 이 페이지 페이지를 편집했습니다.



   - squad도 예시 few shot 넣어준


혜준 안님이 이 페이지 페이지를 편집했습니다.


Perplexity 가 대체 뭐임>??

5 추가 업데이트

Notion
문서, 프로젝트, 위키를 위한
커넥티드 워크스페이스 Notion.so

이메일 설정 업데이트

",일어나 스터디해야지에서 유채은 님 외 3명이 업데이트했습니다,other,read only
194e31b12e099509,"[image: Google]
Windows에서 새로 로그인함
booduck0212@naboocamp.ac.kr
Windows 기기에서 내 Google 계정에 새로 로그인했습니다. 직접 로그인한 것이 맞다면 아무런 조치를 취하지 않아도 됩니다.
본인이 아니라면 안내에 따라 계정을 보호하세요.
활동 확인

다음 페이지에서 보안 활동도 확인할 수 있습니다.
https://myaccount.google.com/notifications
이 이메일은 Google 계정 및 서비스의 중요한 변경사항을 알려드리기 위해 발송되었습니다.
© 2024 Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA
",보안 알림,other,read only
194e31a8c1f2f30f,"[image: Google]
Windows에서 새로 로그인함
booduck0212@naboocamp.ac.kr
Windows 기기에서 내 Google 계정에 새로 로그인했습니다. 직접 로그인한 것이 맞다면 아무런 조치를 취하지 않아도 됩니다.
본인이 아니라면 안내에 따라 계정을 보호하세요.
활동 확인

다음 페이지에서 보안 활동도 확인할 수 있습니다.
https://myaccount.google.com/notifications
이 이메일은 Google 계정 및 서비스의 중요한 변경사항을 알려드리기 위해 발송되었습니다.
© 2024 Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA
",보안 알림,other,read only
194e3181a1674d8e,"[image: Google]
Mac에서 새로 로그인함
booduck0212@naboocamp.ac.kr
Mac 기기에서 내 Google 계정에 새로 로그인했습니다. 직접 로그인한 것이 맞다면 아무런 조치를 취하지 않아도 됩니다. 본인이
아니라면 안내에 따라 계정을 보호하세요.
활동 확인

다음 페이지에서 보안 활동도 확인할 수 있습니다.
https://myaccount.google.com/notifications
이 이메일은 Google 계정 및 서비스의 중요한 변경사항을 알려드리기 위해 발송되었습니다.
© 2025 Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA
",보안 알림,other,read only
194e315a0ba21c8b,"네부캠대학교 에코업혁신융합대학사업단에서는 *""에코업 리더십 개발 캠프""* 참가자를 모집하고자 합니다.


학생분들의 많은 관심과 참여 부탁드립니다.
<figure id='0'><img style='font-size:22px' alt=""에코업혁신융합대학사업단
에코업
리더십
개발 캠프
학생 모집
2025.2.13.(목) ~ 2025.2.14.(금)"" data-coord=""top-left:(11,0); bottom-right:(1242,1042)"" /></figure><p id='1' data-category='paragraph' style='font-size:20px'>프로그램명</p><br><h1 id='2' style='font-size:16px'>에코업 리더십 개발 캠프</h1><h1 id='3' style='font-size:20px'>프로그램 기간</h1><br><h1 id='4' style='font-size:16px'>'25. 2. 13.(목) ~2. 14.(금)</h1><p id='5' data-category='paragraph' style='font-size:18px'>신청 기간<br>~2. 7.(금)</p><br><h1 id='6' style='font-size:20px'>프로그램 주요 내용</h1><br><p id='7' data-category='paragraph' style='font-size:16px'>직업심리검사(MBTI), ESG 특강,<br>증명사진 촬영 지원, 선배와의 만남 등</p><p id='8' data-category='paragraph' style='font-size:20px'>신청 폼</p><br><p id='9' data-category='paragraph' style='font-size:20px'>교육 대상</p><br><h1 id='10' style='font-size:16px'>네부캠대학교 학부생 누구나!</h1><p id='11' data-category='paragraph' style='font-size:20px'>선발 안내</p><br><p id='12' data-category='paragraph' style='font-size:14px'>'25. 2. 7.(금) 개별 안내</p><p id='13' data-category='paragraph' style='font-size:20px'>교육 장소</p><br><p id='14' data-category='paragraph' style='font-size:14px'>서울 소재지 호텔<br>[인원 수에 따라 변경될 수 있음)</p>
",[에코업] 에코업 리더십 개발 캠프 참가자 모집(~2/7선착순마감),other,read only
194e312790654a62,"안녕하세요


2025년도 제1학기 BK지원대학원생 선발 결과를 안내드립니다.


귀 학생은 2025년 제1학기 BK지원대학원생으로 선발되셨습니다. 축하합니다.


한 학기 동안 사업단에 제출한 연구 계획 및 일정에 따라 성실하게 연구 활동에 전념해주길 당부합니다.


더불어, 사업단이 주관하는 각종 행사에 적극적으로 참여해 주시길 부탁드립니다.



4단계 BK21 세계 역사학계를 선도하는 한국 정보 혁신인재 교육연구단 드림



====================================

NAVER BOOSTCAMP UNIVERSITY

세계 정보 통신계를 선도하는 한국 정보 혁신인재 교육연구단


(우) 08888 서울시 관악구 관악로1

정보대학
77동 111호

Tel. 02-888-6789

====================================
",[정보학과BK] 2025년도 제1학기 지원대학원생 선발결과 안내드립니다.,administration,read only
194e310b383c726b,"'2025 지역 창업 솔버톤 대회 데모데이'에 여러분을 초대합니다!

'2025 지역 창업 솔버톤 대회'는 지역 창업 인재들의 우수한 창업 아이디어를 발굴하고 지원하기 위해 전국 대학 창업 지원 9개
기관이 공동으로 개최하는 행사입니다.
데모데이는 서울특별시 강남구에 위치한 한국과학기술회관에서 개최되며, 지역 예선을 통과한 스타트업 30개팀과 투자자, 심사역 등의 30인
심사위원이 참여합니다. 또한 '지역 창업 활성화'를 위한 키노트스피치와 토크콘서트도 준비되어있습니다.

많은 분들께서 참가하셔서, 지역 스타트업으로 성장하는 스타트업을 응원해주시고 다양한 분야의 인사이트와 네트워크도 얻어가시기
바라겠습니다. 현장 등록이 가능하오나 사전 등록이 권장되오니 참석하실 분들은 아래 링크에서 신청하여 주시기 바랍니다.


* 행사명: 2025 지역 창업 솔버톤 대회 데모데이
* 주최: 서울대학교 대학연대 지역인재양성 사업단
* 공동주관: 강원대학교 KNU창업진흥원, 국립순천대학교 창업지원단, 부산대학교 창업지원단, 서울대학교 창업지원단,
울산과학기술원(UNIST) 산학협력단, 전북대학교 창업지원단, 제주대학교 창업지원단, 포항공과대학교(POSTECH) 산학처,
한국에너지공과대학교(KENTECH) 가치창출센터
* 장소: 한국과학기술회관 국제회의실 (강남역 12번 출구에서 300m)
* 대상: 창업에 관심 있는 누구나
* 일시: 2월 20일(월)
* 순서:
10:00~16:00 부스 전시
10:00~10:30 오프닝 및 심사위원 소개
10:30~12:00 IR 피칭 (30개 스타트업)
14:00~16:00 키노트 스피치, 토크 콘서트

* 사전 신청 링크(~2월 16일 14시 기한):
https://docs.google.com/forms/d/13V7b4QyxVoYNfKu1Xo7lvDhG4M9x9VT0U_4nClNe4I0/viewform?edit_requested=true
",[기타]2025 지역 창업 솔버톤 대회 데모데이 초청,other,read only
194e30c2be7b0012,"부덕 박사님, 안녕하세요.

보내주신 제안서 초안 잘 확인했습니다. 내용 정리가 잘 되어 있어서, 내부적으로도 검토가 순조롭게 진행될 것 같습니다.

본격적인 진행 일정을 조율하기 위해 이번 주말 또는 다음 주 초에 간단히 미팅 시간을 잡고 싶습니다. 박사님께서 편하신 시간대
알려주시면, 일정을 확정하여 회의 초대를 보내드리겠습니다.

추가로 논의가 필요한 자료나 궁금한 점 있으면 미리 말씀해 주시면 감사하겠습니다.
그럼 회신 기다리겠습니다.

*쿠자율 드림*

   - KUA자동차 R&D부 과제 담당
   - Tel: 02-3333-1212
   - E-mail: autodrive@kua-auto.co.kr
",KUA자동차 과제 제안서 초안 검토 및 미팅 일정 협의,academic,action needed
194e309f9ec720ee,"부덕 박사님, 안녕하세요.
KUA자동차 연구개발부에서 이번 과제 담당하고 있는 쿠자율입니다.

지난번 협의드린 과제 제안서와 관련하여, 요구사항 자료를 정리한 첨부파일을 보내드립니다.
내용 검토 후 초안 작성에 참고 부탁드립니다.

초안이 준비되시면 전체 진행 일정 및 세부 사항을 논의하고자 하오니, 편하실 때 회신 부탁드립니다.
추가로 문의 사항이 있으시거나 필요한 자료가 있다면 언제든 말씀 주세요.

감사합니다.

*쿠자율 드림*

   - KUA자동차 R&D부 과제 담당
   - Tel: 02-3333-1212
   - E-mail: autodrive@kua-auto.co.kr
",KUA자동차 과제 제안서 관련 요구사항,academic,action needed
194e30413ceac5cf,"어제 카톡에서 얘기한 과제 제안서 말인데, 기업 쪽에서 요구사항 정리가 오면 그 자료 참고해서 초안 좀 작성해봐. 이번 주말 정도까지
한 번 볼 수 있게 해주면 좋겠다.


유채은
- 네부캠대학교 정보학과 교수
- Tel: 010-3939-7878
- E-mail: canolayoo@naboocamp.ac.kr
",KUA자동차 과제 제안서 작성 관련,academic,action needed
194e2fc99430bd98,"안녕하십니까 정보학과 학생회장 우선유입니다.

 먼저 이번 학술제를 더욱 풍성하게 만들기 위해 저희 학생회가 준비한 랩투어 활동에 적극적으로 도움을 주신 각 연구실 여러분께
감사드립니다.

 일전에 전달해드린데로 랩투어 시작 시간은 10:00이고 4개 조로 나누어서 진행할 예정입니다. 각 연구실에서는 간단하게 연구실 소개
(진행하는 연구 및 실험, 주로 사용하시는 실험 기법, 진로 등)를 해주신 후 저희가 사전에 준비한 질문에 대한 답변을 해주시면
됩니다.

 4개 조로 나눈것이 다소 번거로울 수 있으나 교수님 및 학과 조교님과의 회의를 통해 학부생에게 더 효과적인 방향으로 결정된 것이니
부디 이해해주시길 바랍니다.

 여러분들의 노고에 다시 한번 감사드립니다. 문의사항등은 이 메일 주소로 메일 주시면 답변 드리도록 하겠습니다.
",[네부캠대 정보학과] 학술제 오픈랩 관련 공지,academic,action needed
194e2faf9058a111,"안녕하십니까. 정보학과 학생회장 우선유, 부학생회장 준혜안입니다.

다름이 아니라 학술제와 관련하여
연구실에 여쭤볼 게 있어 메일을 드리게 되었습니다.

저번에 정보학과 학술제 초대장 및 타임라인을 전달드렸는데,
혹시 각 연구실이 학술제 및 간담회(학술제 뒷풀이)에 참여가 가능하실지,
참여하신다면 몇 명 정도 참여가 가능하실지
참여 여부를 여쭙고 싶어 메일을 드리게 되었습니다.

연구실별
1. 학술제 참여 여부 및 참여자 명단
2. 간담회(학술제 뒷풀이) 참여 여부 및 참여자 명단

이 두 가지를 메일로 회신해주시면
보다 원활한 행사 진행에 도움이 될 것 같아 부탁을 드리고자 합니다.


많이 바쁘시지만 정보학과 학생들이 열심히 준비한
학술제 연구 발표를 진행하오니 와주셔서 많은 조언을 해주신다면
더욱더 뜻깊은 학술제가 될 것 같아 시간이 되신다면 많은 참여 부탁드립니다.

바쁘신와중에도 학과 행사에 많이 도움을 주시고 협조해주셔서 늘 감사드립니다.

- 정보학과 학생회장 우선유, 부학생회장 준혜안  올림
",[네부캠대 정보학과] 학술제 및 간담회 참여 여부,academic,action needed
194e2f8a6303ffb0,"안녕하십니까. 정보학과 학생회장 우선유입니다.

먼저 앞서 보낸 오픈랩(=랩투어) 행사 관련 공지 메일과 관련하여
문의 메일들을 받게 되었고, 문의해주신 사항들이 저희가 처음에 보낸 메일에
미처 보내지 못한 중요한 내용들이라고 생각이 되어

문의사항에 대한 답변 및 추가적인 오픈랩 행사 진행 관련 사항에 대해
전체 공지 및 안내를 해야될 것 같아 메일을 한번 더 보내게 되었습니다.

오픈랩 행사 진행 관련하여 정해진 사항은 다음과 같습니다.

- 일시 : 2025년 2월 12일 오전 10:00~오전 11:00

- 오픈랩 참여 학부생 : 총 4조로 나누어 진행 (각 조당 10명 내외)

- 오픈랩 사전 질문
  1) 오픈랩 행사 참여 학부생 대상 사전질문 조사 구글폼 배부
       -> ~ 2/5, 오후 6시 마감
  2) 집행부 내부에서 사전 질문 취합 및 정리
  3) 각 연구실에 사전질문 전달
       -> 메일로 전달 예정
       -> 금요일(2/7) 오전에 전달 예정
           (일정 지연이 발생하면 늦어도 2/10 오후 2시전에 전달 예정)
           (연구실별로 나온 사전 질문 전달 예정)

- 연구실별로 오픈랩 진행 시간 및 진행 내용
  1) 진행 시간 : 한 연구실당 7분
  2) 진행 내용
        : 연구실에서 진행하는 연구 및 실험, 주로 사용하는 실험 기법, 진로 -> 5분
          사전 질문 답변 , 현장 질문 -> 2분
          * 대략적인 진행 내용 및 시간을 임의로 정한 것이니
             연구실에서 자유롭게 조정하셔서 진행하시면 됩니다!
          * 한 연구실 당 7분이라는 총 시간만 맞추시면 됩니다.
          * 7분보다 많은 시간이 소요되면 부득이하게도 이후 행사가 지연되어
             행사 진행에 어려움이 있을 수 있어 인솔팀이 이동해야한다고
             말할 수 있습니다.. 많은 시간을 확보하지 못해 죄송하고
             이 점 양해 부탁드립니다....
",[네부캠대 정보학과] 오픈랩 행사 관련 전체 공지,academic,read only
194e2f525110b087,"안녕하십니까. 정보학과 학생회장 우선유입니다.

공통 질문과 각 연구실별 궁금한 질문사항들을 조사하였는데
연구실별 질문 사항들이 진로, 역량 등 비슷한 사항이라
전체 메일로 전달드립니다.

공통 질문
1. 대학원 입시 과정 및 준비해야할 것
2. 대학원에 가면 듣는 수업
3. 학부생일때와 학비 비교
4. 대학원생의 하루 일과는 어떤지
5. '정보대는 대학원이 필수다.'라는 말을 어떻게 생각하시는지
6. 실험실 선택 시 제일 중요하게 생각하셨던 요소들
7. 해외로도 대학원 및 취업을 많이 하시는지

연구실별 질문
1. 연구실에서 원하는 인재상
2. 대학원 졸업 후 취업 및 진로

사전질문은 위와 같고,
집행부에서 부탁드렸던 연구실 소개 내용과
중복되는 질문은 연구실 소개하실때 통합해서
말씀해주시면 될 것 같습니다.

학부생들이 현장 추가 질문이 있으면
간단하게 답변해주시면 감사할 것 같습니다.

아울러 내일 당일 현장 진행 상황 및
이후 스케줄 변동으로 인해
오픈랩 연구실별 7분으로 예정되어있던 시간이 6분정도로 감소될 수 있고,
현장에서 변경되었을 경우 현장 인솔팀원이
시간 감소 등의 변경사항 전달드릴 예정이니 이 점 양해 부탁드립니다.

처음 진행 및 시도하는 행사라 많은 시행착오가 있어
많은 양해를 구하게 된 점 죄송하고 감사합니다.

- 정보학과 학생회장 우선유 올림.
",[네부캠대 정보학과] 학술제 오픈랩 사전질문 관련 추가 공지,academic,read only
194e2f16e3fde487,"박부덕 조교님께,

조교님, 답장 감사드립니다. 그러면 별도로 확인하지 않아도 괜찮을 것 같습니다.
한 학기 동안 수고 많으셨습니다. 감사합니다.

호채이 올림.
",RE: RE: [응용파동광학] 시험지 확인 문의드립니다,administration,read only
194e2f0965da81ab,"박부덕 조교님께,

조교님, 안녕하세요. 응용파동광학 수강생 호채이입니다. (학번: 20211234)
제가 급한 일로 본가에 내려가게 되어 월요일 클레임 세션에 참석하지 못하게 되어 연락드리게 되었습니다.

혹시 원격으로 시험지 또는 문항별 점수를 확인할 수 있는 방법이 있을까요?
만약 어려우시다면 말씀만 주셔도 감사드리겠습니다.

즐거운 주말 보내시고, 바쁘신데 메일 확인해주셔서 감사드립니다.
감사합니다!

호채이 올림.
",[응용파동광학] 시험지 확인 문의드립니다,administration,action needed
194e2ef286fe8c4d,"안녕하세요, 박부덕 조교님.

보내주신 메일 확인하였으며, 먼저 제 불찰로 인해 실습 코드가 외부에 공개된 점 정말 죄송합니다.

말씀해주신 내용을 바탕으로 *해당 코드는 즉시 GitHub에서 삭제 처리*하였으며, 추가로 문제될 소지가 있는 부분이 있는지 확인
중입니다.

이번 일로 인해 불편을 끼쳐드려 정말 죄송합니다. 혹시라도 추가적으로 처리해야 할 사항이나 문제가 발견되면 즉시 조치하겠습니다.

감사합니다.
안혜준 드림
",RE: 깃허브 및 개인 홈페이지 관련 문의 메일,other,read only
194e2eda0fa4a5ce,"네, 채점에 별다른 문제가 없었는지요?

문제가 없었다면 KLMS에 성적을 공지해 주시기 바랍니다. 이후, 클레임이 있는 학생들의 의견을 수렴한 뒤, 정해진 기간 내에 성적을
확정하면 될 것 같습니다.

민캠퍼 드림
",Re: [PH621] 응용파동광학 기말고사 채점 완료,administration,action needed
194e2ec52174eb7e,"답안지는 별도로 제공되지 않으며, 홈페이지에 공개하지 않을 예정입니다. 다만, 시험지를 수령한 후 답안에 대해 논의하는 것은
가능합니다. 문제 자체는 어렵지 않으므로 기준을 정해 채점하시면 될 것 같습니다.
혹시 채점 기준이나 해답 중 명확하지 않은 부분이 있다면 언제든지 저에게 알려주세요. 채점 자체는 되도록 빠른 것이 좋겠습니다 (이번
주 일요일 정도?).

민캠퍼 드림
",Re: [PH621] 응용파동광학 기말고사 채점 관련,administration,action needed
194e2ead837b50a2,"내일 기말고사 시험지입니다. 문제 있는 경우 알려주세요.

시험 진행 시 문제가 있는 경우, 010-1234-5678로 전화 주세요.

민캠퍼 드림
",[PH621] 응용파동광학 기말고사 시험지 확인,administration,action needed
194e2e88da552d43,"다른 강의실과 수용 인원이 비슷하지 않은가요?

확인 후 알려주세요. 빨리 알려주셔야 강의실 공지를 올릴 수 있습니다.

민캠퍼 드림
",Re: [PH621] 응용파동광학 기말고사 시험 강의실 관련,administration,action needed
194e2e56a9cb3c7c,"안녕하세요, 학적팀 류이열입니다.

창의관 202호 배정하였습니다.
다음부터는 과목번호, 과목명, 담당교수님 성함, 시작시간, 종료시간, 수강인원 정보를 이메일로 보내주시기 바랍니다.
(정규 수업/시험의 경우 신청서 양식 제출 불필요)

감사합니다.
류이열 드림

*류이열* Eyeol, Ryu
학적팀 / Academic Registrar's Team
",RE: 창의학습관 강의실 예약 관련 문의 - 정보학과 박부덕,administration,read only
194dfd94f9743bd1,"[image: GitHub]How to get started with GitHub Copilot.


[image: GitHub Copilot]
Welcome to GitHub Copilot.
Here’s how to get started.

You now have access to GitHub Copilot in VS Code and github.com for free as
part of your GitHub user account—and that includes support for models from
OpenAI and Anthropic.
Ask Copilot how to get started 

What’s included:

   - 2,000 intelligent code completions a month: Get context-aware code
   suggestions that draw context from your GitHub projects and VS Code
   workspace.
   - 50 Copilot Chat messages a month: Ask Copilot for help understanding
   code, refactoring something, or debugging an issue.
   - Choose your AI model: Pick between Claude 3.5 Sonnet or OpenAI GPT-4o.
   - Make changes to multiple files with Copilot Edits: Tackle changes
   across multiple files with Copilot Edits.
   - Support for the Copilot Extensions ecosystem: Access third-party
   agents designed for tasks such as querying Stack Overflow or searching the
   web with Perplexity.
   - Choose where you build: Enjoy support in VS Code and across GitHub.

So, what will you build?

P.S. - Not sure where to start?
Try these Copilot Chat prompts


Copilot Settings
*GitHub Copilot will show code suggestions that match public code
,
including code references in the VS Code and github.com 
experience. GitHub and affiliates may use your data for product
improvement. You can adjust both data use and public matching code
suggestion settings in your Copilot Settings
.*


Privacy policy 
 ・ Terms of use

 ・ Contact us 




GitHub, Inc. ・88 Colin P Kelly Jr Street ・San Francisco, CA 94107
",GitHub Copilot: What’s in your free plan 🤖,other,read only
194dfd33e8b5fdc0,"안녕하세요. 퀸카피 입니다.

스캔파일 입니다.
원본은 내일 오후에 찾으러 오시면 됩니다.

스캔비용 52,600원
스프링     5,000원
합계      57,600원

퀸카피
인쇄사무편의점 - 복사, 출력, 제본, 논문, 각종인쇄
",퀸카피...스캔파일 입니다.,other,action needed
194dfd0cc6227538,"박부덕 님께

안녕하세요. 네부캠대학교 산학협력단입니다.
아래 연구과제에 대한 2025년  1월 인건비 입금(세금제외)이 완료되었음을 알려드립니다.


○ 지급과제정보
  * 지원기관    : 네부캠 교육부
  * 시행기관    : 네부캠 연구재단
  * 지원사업    : 4단계 부캠21사업
  * 세부사업    : 네부캠인재양성사업
  * 연구과제    : A0123-20244567
  * 연구과제명  : 친환경 디지털 정보 교육연구단
  * 연구책임자  : 부이열
  * 연구기간    : 2024-03-01 ~ 2025-02-28
  * 수령계좌번호 : (기업은행)1232123212321
  * 인건비 청구액 : 1,000,000 원
    - 세금징수액 0 원
    - 실수령액 1,000,000 원

■ 인건비 지급 상세 확인 : SRnD 로그인>연구자정보관리>인건비 지급조회 메뉴에서 개인별 상세 내역 확인 가능합니다.
* 본 메일은 발신 전용이므로 회신하실 경우 답변이 되지 않습니다.
",인건비 지급 안내 메일,administration,read only
194dfcdcd23e0a07,"*▶보건진료소 심폐소생술 교육 홈페이지 [심폐소생술 교육 예약 바로가기] http://cpr.naboocamp.ac.kr
*

2025학년도 심폐소생술 교육 안내

○ 대상 학생 및 교직원 (매년 1회 가능) ＊온라인 예약 필수
○ 일시 매주 월,수,금/ 매월 마지막 주에는 화,목 (12/23~2/7 : 14:00~17:00) (공휴일 등 휴강일 제외)
○ 장소 네부캠퍼스 체육관(12동) 345호
○ 문의 cpredu@naboocamp.ac.kr <cpredu@snu.ac.kr> / 02-888-2345
※ 단체 교육 신청 가능(최소 6인 이상, 교육일 기준 최소 1~2개월 전, 심폐소생술 교육 메일로 신청:
cpredu@naboocamp.ac.kr <cpredu@snu.ac.kr>)




*▶ 유의사항※ 감기 등 감염성 질환/ 기브스 착용 등으로 실습 참여가 불가한 경우 교육참여가 불가합니다.    추후 회복 후 교육에
참석해 주시기 바랍니다.- 예약시간을 꼭 지켜주시기 바랍니다.*
",[보건진료소]2025학년도 심폐소생술 교육 안내,administration,action needed
194dfca56b171603,"안녕하세요. 정보학과 행정실입니다.

네부캠대학교 정보학과에서 총 3회에 걸쳐* '정보학과 특강: 새로운 시대를 위한 대담한 통찰'*을 개최합니다.
자세한 내용은 정보학과 홈페이지 공지를 참고 부탁드립니다.

<제 2회 인공지능, 새로운 눈으로>
*1. 일시 :* 2025. 1. 29(수) 오후 4시~
*2. 장소 : 부캠관 B101호*
*3. 참가대상:  *네부캠대학교 구성원(학부 및 대학원 재학생과 교원 및 교직원 모두)

<제 3회 사례로 보는 AI 활용 범죄에 대한 기술적 접근>
*1. 일시 :* 2025. 2. 03(월) 오후 3시 30분~
*2. 장소 : 부캠관 B101호*
*3. 참가대상: *네부캠대학교 구성원(학부 및 대학원 재학생과 교원 및 교직원 모두)


...

[Message clipped]  View entire message

","[인공지능학부] 제 2회, 3회 정보학과 특강 개최 참가신청(1/28까지, 선착순)",academic,action needed
194dfc2d81335274,"<h1 id='0' style='font-size:18px'><전체 구성원 대상></h1><h1 id='1' style='font-size:22px'>K-CLASS 활용 구성원 설문조사</h1><p id='2' data-category='paragraph' style='font-size:14px'>학부대학 원격교육센터는 교내 교육 콘텐츠를 종합 관리하는 플랫폼으로 K-CLASS를<br>2024년 11월에 구축하여 운영 중에 있습니다.<br>이에 본교 구성원을 대상으로 설문을 통해 K-CLASS에 탑재할 콘텐츠의 개발 방안을 도출하고자 합니다.<br>응답해 주신 내용은 향후 온라인 콘텐츠 개발에 중요한 참고자료로 활용될 것입니다.<br>바쁘시더라도 잠시만 시간을 내시어 응답해 주시기를 부탁드립니다.</p><h1 id='3' style='font-size:16px'>관련 문의: 02-3290-5071</h1><h1 id='4' style='font-size:20px'>설문 기간: 2025년 1월 10일~20일</h1><h1 id='5' style='font-size:20px'><K-CLASS란?></h1><p id='6' data-category='paragraph' style='font-size:18px'>K-CLASS는 고려대를 상징하는 K와 학습 공간을 의미하는 Class의 합성어로<br>1<br>양질의 고려대학교 영상 콘텐츠에 누구나 어디서든 쉽게 접근할 수 있도록<br>새롭게 선보이는 E-러닝 서비스입니다.</p><p id='7' data-category='paragraph' style='font-size:14px'>2</p><br><p id='8' data-category='paragraph' style='font-size:16px'>K-CLASS는 인문학, 비즈니스/경제, 과학 등 총 10가지 강의 주제로 분류된<br>「 열린강좌 」 와 디지털 정보화시대에 발맞추어 특성화한 「 AI 」 및 「 Data<br>Science」의 메뉴로 구성하였습니다.</p><p id='9' data-category='paragraph' style='font-size:22px'>K-<br>CLASS</p>



▼



*K-CLASS 바로가기*

https://k-class.naboocamp.ac.kr/ 



*<설문 링크>*

*https://forms.gle/LwgN5fCvZxgdgg3Zd7 *



*<For all members>*



*Survey of members using K-CLASS*



Distance Education Center of the University College is operating K-CLASS, a
platform that comprehensively manages on-campus educational content, with
full implementation expected by November 2024. Accordingly, we would like
to develop plans for content to be loaded onto K-CLASS through a survey of
our members. The information you provide will be used as important
reference material for future online content development. Please take a
moment to respond, even if you are busy.

For inquiries: 02-1992-2023



*Survey period: January 10-20, 2025*



K-CLASS is a combination of 'K,' which symbolizes Korea University, and
'Class,' which refers to a learning space. It is a new e-learning service
that allows anyone to easily access high-quality Korea University video
content, anywhere.



K-CLASS consists of 'Open Lectures' categorized into 10 lecture topics,
including Humanities, Business/Economy, and Science, as well as sections on
'AI' and 'Data Science' designed to keep pace with the digital information
age.




▼



*GO! K-CLASS*

https://k-class.korea.ac.kr/



*<Survey Link>*

https://forms.gle/LwgN5fCvZxcmy3Zd7

...

[Message clipped]  View entire message

",[원격교육센터] K-CLASS 활용 구성원 설문조사 (Survey of members using K-CLASS),administration,read only
194dfbd0fc5109ce,"안녕하세요 네부캠대학교 학업코칭입니다.


'1:1 학업코칭'은 학업에 대한 걱정이나 불안, 학교 생활에서의 스트레스, 시간 관리 문제, 학업에서 원하는 목표 달성 등 학업과
관련된 다양한 부분에서 도움을 드리는 프로그램입니다.

남은 방학 전략적인 수강신청 및 새 학기를 알차게 준비하고 싶은 학부생들께서는 1:1 학업코칭을 신청해주세요!


신청 시 바로 접수 면담 일정 조율을 위한 연락을 드립니다.

(희망 시 메타버스 플랫폼을 통한 비대면 코칭도 가능합니다!)



문의 사항이 있는 경우,

02-3290-1234 또는 learninghigh@naboocamp.ac.kr로 연락주시길 바랍니다.
",[학업코칭] 남은 방학 1:1 학업코칭으로 알차게 마무리!,administration,read only
194dfbb1d90e4b8a,"학부생 및 대학원생 여러분,

안녕하세요.
네부캠대학교 정보학과 사무실 유이열입니다.

우리 학과는 매월 학과 소식지를 발행하고 있습니다.
이에 2025년 2월 학과 소식지가 발행되어 송부해 드리오니 많은 관심 부탁드리겠습니다.
감사합니다.

1. 소식지 링크: https://naoe3. naboocamp.ac.kr/news/newsletter

 (*링크가 열리지 않을 경우 첨부 파일 확인)

2. 문의: 네부캠대학교 정보학과 사무실 유이열(yey@naboocamp.ac.kr <yey@snu.ac.kr>, 02-888-7654)


쌀쌀한 날씨에 건강 유의하시고 안녕히 계세요.


네부캠대학교 정보학과 유이열 올림.


*유은영*
정보학과
서울시 관악구 관악로 1, 23동 456호
Tel 02-888-7654   Fax 02-888-9876
Email  yey@naboocamp.ac.kr <yey@snu.ac.kr>
",[네부캠대학교-정보학과] 학과 소식지 2025년 2월호 발송,academic,read only
194dfb50dd4b0e4e,"* 본 메일은 전체 메일로 발송되었습니다.

안녕하세요.
정보대학 미래교육연구원입니다.

2025 상반기 미래교육포럼 개최를 안내합니다.

오는 *2/10(월요일) 15시*에 *'AI/디지털 기반의 교육생태계'*를 주제로 유채은 장학관님(서울시교육청
디지타루헤쿠신미라이교육과)과 교육 현장의 디지털 이슈와 변화에 대해 이야기 나눌 예정입니다.
두번째 포럼은 3월에 '기후변화시대의 환경시민성'을 주제로 김네부 교수님(업스테이지대학교 환경교육과)과 기후변화의 쟁점과 시민참여 및
실천에 대해 논의합니다.

본 행사는 온라인으로도 동시 송출되며 참여링크는 아래와 같습니다. .
온라인 참여링크:
https://naverboostcamp-ac-kr.zoom.us/j/8997741432?pwd=wXyPnsf3FhEVIKniH9vdjB58jyrviN.1&omn=88274343839

많은 분들의 관심과 참여를 바랍니다.
감사합니다.
","리마인드, [정보대학 미래교육연구원] 2025년 상반기 미래교육포럼 안내",academic,read only
194dfb0df0832f72,"현재 공사 진행 중인 자연계 정운오IT 교양관 공사와 관련하여 건물 앞 도로 및 인도 공사와 관련하여 사전 안내드립니다.

자연계 교양관은 올해 2월 준공을 목표로 하고 있습니다.

그러나 건물 이용 시 주출입구 앞 계단이 차량 통행 도로와 바로 연결되어 건물 이용 시 사용자의 안전 문제가 우려됩니다.

이를 해결하고 보행 편의를 위해 아래와 같은 공사를 진행할 예정입니다.


공사 주요 내용

   1.

   보행로 이전
   -

      현재 이학별관쪽 보행로를 자연계 교양관 쪽으로 이전 설치(보도블럭 포장)
      -

      미래융합기술관에서 자연계 교양관을 거쳐 노벨광장까지 이어지는 새로운 보행로 설치






      2.

   도로 재포장
   -

      돌로 포장된 기존 도로를 철거 (다수 파손 및 안전사고 우려)
      -

      차량 안전을 위해 아스팔트 도로로 새롭게 재포장 (자연계 중앙광장 공사 시 이용예정)






      3.

   가로수 부분 정비
   -

      새로운 도로 부지 확보를 위해 부득이하게 일부 가로수를 정비해야 하는 상황입니다.
      -

      이 정비는 보도의 안전성을 높이고 공간 효율성을 고려하여 부득이하게 결정된 사항입니다.





추가 안내

   -

   보행자 및 차량은 통행이 금지되오니 우회하여 주시기 바랍니다.
   -

   내년 착공 예정인 ""자연계 중앙광장 공사"" 기간 동안 공사차량이 해당 도로를 이용할 예정입니다.
   -

   공사 완료 후, 외부의 주차장은 지하화되고 상기 도로는 보행자 전용도로로 전환 될 예정입니다.


연이은 공사로 인해 불편을 끼쳐드리게 되어 죄송합니다.

구성원 여러분의 안전과 편의를 위한 조치이므로 너른 양해를 부탁드립니다.
",[관리처] 자연계 정운오IT교양관 준공에 따른 도로 및 보도 공사 계획 사전 안내,administration,read only
194dfaec72bb288b,"교우님, 안녕하십니까.

네부캠대학교 정보대학장 강감찬입니다.


12월까지도 다사다난 했던 2024년도가 벌써 지나가고 벌써 2025년이 되었습니다.

2024년에 40주년을 맞이한 정보대학은 여러분의 적극적인 지원과 성원으로 여러 행사를 잘 치러내고,

정보대가 앞으로 나아갈 미래를 짚어 보는 소중한 해였던 것 같습니다.


40주년을 기념하여 기부 Drive와 교우회 등록 행사는

info-40.korea.ac.kr을 통하여 내년에도 지속되고 있으니 계속적인 관심 부탁드립니다.

내년에도 여러분의 모교인 고려대학교 정보대학이 발전할 수 있도록 노력하겠습니다.

그리고 교우 여러분 가내에 새해 복 많이 받으시고 항상 건강 기원드립니다.


감사합니다.

강감찬 배상.
",네부캠대학교 정보대학 교우님께,other,read only
194dfa9f3bdf6252,"

*나 그리고 우리 둘을 위한 플랜, 듀오*
[image: 나 그리고 우리 둘을 위한 플랜, 듀오]



*듀오로 업그레이드 하고 더 적은 비용으로2개의 프리미엄 계정을 사용하세요*

좋아하는 음악 취향까지 알아가고 싶은 사람이 있나요?
함께하는 시간을 쌓고 서로의 음악 케미를 확인할 수 있는
듀오를 시작해보세요.

*나만의 플레이리스트는 여전히 그대로*

각자의 계정으로 오롯이 당신만을 위한 새로운 데일리 믹스,
새 위클리 추천곡 플레이리스트도 즐길 수 있습니다.
듀오로 업그레이드 하기


*매월 16,350원(부가세 별도)이 적용됩니다. 이용 약관이 적용됩니다.
*
[image: Spotify Logo]
------------------------------
다음 기기에서 Spotify 가입하기:  iPhone

 iPad

 Android

 기타

------------------------------
이 메시지는 modumchobab@gmail.com(으)로 전송되었습니다. 앞으로 이러한 이메일을 받지 않으려면 프로필을 편집

하거나 구독을 해지

하세요.
사용 약관

 개인정보처리방침

 문의하기

Spotify AB, Regeringsgatan 19, 111 53, Stockholm, Sweden
",화이트데이엔 듀오로 마음을 표현하세요!,other,read only
194dfa8c096434dd,"제 5348호
2025.01.08 당신의 하루가 특별하기를 서울시가 응원합니다 [image: 동행 매력 특별시 서울]

[image: 내손안에서울]

[image: 올해는 완주 도전! '쉬엄쉬엄 한강 3종' 8일부터 사전 신청]

올해는 완주 도전! '쉬엄쉬엄 한강 3종' 8일부터 사전 신청

[image: 기후동행카드 이용하면 보험 <br>무료 가입…최대 2천만원 보장]

기후동행카드 이용하면 보험
무료 가입…최대 2천만원 보장
#진단비 #치료비 #위로금 #보장기간_1년
#15세이상 #미니보험_가입방법

신혼부부·청년 전세대출 이자
지원…신청은 이렇게!
#임차보증금_이자지원 #다자녀가구
#결혼7년이내 #6개월이내_결혼예정

[image:
신혼부부·청년 전세대출 이자<br>지원…신청은 이렇게!]

[image: 국내에서 가장 많이 이용하는<br>김포공항, 안전한지 살펴보니…]

국내에서 가장 많이 이용하는
김포공항, 안전한지 살펴보니…
#한우진_교통칼럼 #김포공항
#안전관리 #조류충돌예방

[image: 기발한 뉴스 / 시민기자가 발로 뛰며 취재한 뉴스]

시민기자 김재형
장애인주차구역에 불법주차, 스마트지킴이가 보고 있어요!
#약자동행 #장애인주차 #국가유공자

시민기자 김아름
'아듀, 서울윈터페스타!' 꿈만 같았던 순간 다시 돌아보기
#광화문광장 #겨울명소 #스케이트장


시민기자 김미선
에너지를 아껴주는 똑똑한 집을 만나다 '그린리모델링 홍보관'
#에너지절약 #그린에너지센터 #친환경

시민기자 조송연
추워도 한강 나들이는 포기 못한다면? 따듯한 전망카페가 답!
#전망맛집 #데이트카페 #모임장소

[image: 가장 인기있는 뉴스]

서울시, 2025 민생경제 회복 총력…정책자금 2일부터 접수

저축액 2배 매칭! '디딤씨앗통장' 가입대상 확대…신청은?

서울 어디서든 쏠쏠~ 새해 첫 '서울사랑상품권' 8일 발행

불필요·불합리한 규제 신고하세요! '집중신고제' 100일간 가동

'서울플래너'와 함께 새해 계획 세워볼까? 디자인·실용성 만족

[image: 미세먼지 불법배출신고]

[image:
서울청년정책네트워크]

[image: 오늘 레터 공유]

[image: 지난 뉴스레터]

[image:
뉴스레터 구독]

[image:
검은색이미지] [image: 서울시 유튜브]

[image:
서울시 페이스북]

[image:
서울시 트위터]

[image:
서울시 블로그]

[image:
라이브 서울]

[image:
서울시 인스타그램]

[image:
서울시 플러스친구]

[image: 서울특별시 푸터]
[image: 수신거부]
",올해는 완주 도전! '쉬엄쉬엄 한강 3종' 8일부터 사전 신청,other,read only
194dfa30055422e1,"[image: Description: awslogo]



AWS Free Tier usage limit alerting via AWS Budgets 01/28/2025

Dear AWS Customer,
Your AWS account 908027378622 has exceeded 85% of the usage limit for one
or more AWS Free Tier-eligible services for the month of January.
Product AWS Free Tier Usage as of 01/28/2025 Usage Limit AWS Free Tier
Usage Limit
AmazonVPC 646 Hrs 750 Hrs 750.0 Hrs for free for 12 months as part of AWS
Free Usage Tier (Global-PublicIPv4:InUseAddress)
AmazonEC2 25.92741894 GB-Mo 30 GB-Mo 30.0 GB-Mo for free for 12 months as
part of AWS Free Usage Tier (Global-EBS:VolumeUsage)
AmazonEC2 645 Hrs 750 Hrs 750.0 Hrs for free for 12 months as part of AWS
Free Usage Tier (Global-BoxUsage:freetier.micro)
To learn more about your AWS Free Tier usage, please access the AWS Billing
& Cost Management Dashboard
.
You can find more information on AWS Free Tier here

.
*This alert is provided by AWS Budgets
.
AWS automatically tracks your service usage and will alert you if you have
reached 85% of the usage limit for one or more AWS Free Tier-eligible
services. To unsubscribe from these alerts or to change the email address
to which you would like your alerts to be sent, please visit the Cost
Management Preferences
.*






Please do not reply directly to this email. If you have any questions or
comments regarding this email, please contact us at
https://aws.amazon.com/support


This message was produced and distributed by Amazon Web Services, Inc., 410
Terry Avenue North, Seattle, Washington 98109-5210. AWS will not be bound
by, and specifically objects to, any term, condition or other provision
which is different from or in addition to the provisions of the AWS
Customer Agreement or AWS Enterprise Agreement between AWS and you (whether
or not it would materially alter such AWS Customer Agreement or AWS
Enterprise Agreement) and which is submitted in any order, receipt,
acceptance, confirmation, correspondence or otherwise, unless AWS
specifically agrees to such provision in a written instrument signed by AWS.

맨위로 
",AWS Free Tier limit alert,other,read only
194dfa18daef2cc6,"[image: WakaTime Logo]




Weekly code stats for 2025-01-27 until 2025-02-02


8 hrs 43 mins
total
1 hr 27 mins
daily average

Categories:
*Coding* 8 hrs 43 mins
Projects:
*side-project* 8 hrs 24 mins
*algorithm_practice* 15 mins
*toy-project* 3 mins
Languages:
*Python* 4 hrs 45 mins
*Text* 1 hr 44 mins
*YAML* 1 hr 38 mins
*JSON* 14 mins
*Git* 13 mins
*Other* 3 mins
*Bash* 3 mins
Editors:
*VS Code* 8 hrs 43 mins
Operating Systems:
*Linux* 8 hrs 24 mins
*Mac* 18 mins
Machines:
*instance-14461* 8 hrs 24 mins
*Nocturne.local* 18 mins







[image: X]  [image: GitHub]
 [image: Reddit]



Upgrade to WakaTime Premium


Share these email reports .

Too many emails? Switch to monthly emails
.

To stop receiving *Weekly report* emails, unsubscribe

.

*Copyright © 2025 WakaTimeAll rights reserved.*
",[weekly] report for 2025-01-27 until 2025-02-02,other,read only
194df9af2a198324,"ICT명품인재양성사업단에서 다양한 AI 서비스 개발을 위한 “LLM Innovators challenge” 경진대회를 개최하오니
네부캠대학교 학부/대학원생들의 멋진 아이디어를 세상에 보여주세요!!

*※* 자세한 사항은 홈페이지 확인 [경진대회 홈페이지 바로가기]




*● 대회 주제:* 업스테이지가 제공하는 LLM API를 활용한 다양한 AI 서비스 개발

*● 참가 대상:* 네부캠대 학부/대학원생 누구나 (개인 or 팀)

*● 신청 방법:* *2025. 3. 13 (**금)*까지 온라인 신청서 작성 [신청 링크 바로가기]


● *상금 및 상품: 총 2천만원*

(대상 1천만원 / 우수상 5백만원 / 장려상 3백만원 / 인기상(2팀) 각 1백만원)

●* 대회 일정*

*구분*

*일자*

참가등록

3/13 (금) 까지

예선

3/20 (금) ~ 4/6 (일)

예선심사

4/7 (월) ~ 4/9 (수)

본선

4/10 (목) ~ 4/16 (수)

최종발표 및 심사

4/17 (목)

데모 및 시상

10/18 (금)


● *평가 기준: *홈페이지에서 확인 [경진대회 홈페이지 바로가기]




*문의) ICT명품인재양성사업단 02-3210-8765*
",[명품인재×업스테이지] “LLM Innovators challenge” 에 도전해보세요!! (~3/13),administration,action needed
194df976f350f38a,"네부캠대학교 ICT명품인재양성사업단/초지능연구센터는 작년에 이어 올해 2월 14일(금)에 AI Tech Day를 개최합니다.

본교 하나스퀘어에서 열리는 AI Tech Day 2025에서는 사업단 소속 교수들이 올해 발표한 top-tier conference
논문과 현재 진행 중인 연구를 결합하여 압축 발표하고, 네닛, 부캠소프트, SW, CH, 이열오사AI, 업스테이지의 AI 연구개발
책임자들이 각 기업의 AI 연구개발 성과와 미래 전략을 발표합니다.

여기에 더불어, 사업단 소속 연구실의 포스터와 데모 세션이 준비되고, 기업체 홍보 및 리크루팅 프로그램도 마련됩니다.

AI의 현재와 미래를 보고자 하는 분들의 많은 참석 바랍니다.


AI Tech Day 2025 조직위원장 유선우, 공동 프로그램 위원장 이채호, 단이열 드림



★ 행사 홈페이지: AI Tech Day 2025 소개


★ 사전등록 바로가기: AI Tech Day 2025 사전등록

<h1 id='0' style='font-size:20px'>2024</h1><br><h1 id='1' style='font-size:22px'>AI TECH<br>DAY</h1><br><h1 id='2' style='font-size:16px'>네부캠대학교 정보대학 40주년<br>U Pioneering the next Intelligence</h1><h1 id='3' style='font-size:20px'>2025년 2월 14일 (금)<br>네부캠대학교 하나스퀘어</h1><br><h1 id='4' style='font-size:18px'>주최</h1><br><h1 id='5' style='font-size:14px'>네부캠대학교 정보대학<br>ICT명품인재양성사업단/초지능연구센터</h1><h1 id='6' style='font-size:18px'>문의 및 등록</h1><br><h1 id='7' style='font-size:14px'>* 사전 및 현장 등록 (무료)<br>* https://ku-ai-techday2024.veroelapp/</h1><br><h1 id='8' style='font-size:16px'>홈페이지</h1>
",AI Tech Day 2025 - 02/13(목) 정오 사전등록 마감,academic,action needed
