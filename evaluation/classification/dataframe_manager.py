import os

import pandas as pd

from .metric_calculator import MetricCalculator


class DataFrameManager:
    """
    ë¶„ë¥˜ ê²°ê³¼(ë©”ì¼ ID, Ground Truth, NíšŒì°¨ Inference ë“±)ë¥¼ ê´€ë¦¬/ì €ì¥í•˜ê³ ,
    MetricCalculatorë¥¼ í˜¸ì¶œí•´ í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” ì±…ì„.
    """

    def __init__(self, inference_count: int):
        self.inference_count = inference_count
        self.output_dir = "evaluation/classification"
        os.makedirs(self.output_dir, exist_ok=True)
        self.csv_file_path = os.path.join(self.output_dir, "labeled.csv")

        self.columns = (
            ["mail_id", "ground_truth"]
            + [f"inference_{i+1}" for i in range(inference_count)]
            + ["entropy", "diversity_index", "chi_square_p_value", "accuracy", "cramers_v"]
        )

        if os.path.exists(self.csv_file_path):
            self.eval_df = pd.read_csv(self.csv_file_path)
            print(f"ğŸ“„ ê¸°ì¡´ í‰ê°€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.eval_df.shape[0]}ê°œì˜ ë°ì´í„°")
        else:
            self.eval_df = pd.DataFrame(columns=self.columns)

    def update_eval_df(self, mail_id: str, results: list, ground_truth: str):
        """
        1) ë©”ì¼ ID ì¤‘ë³µ ì²´í¬
        2) ë©”íŠ¸ë¦­(Entropy, Diversity, p-value, Accuracy, Cramer's V) ê³„ì‚°
        3) CSVì— ë³‘í•© ì €ì¥
        """
        # ì´ë¯¸ ì²˜ë¦¬ëœ ë©”ì¼ì¸ì§€ í™•ì¸ + ëª¨ë“  inference ì¹¼ëŸ¼ì´ ì±„ì›Œì¡ŒëŠ”ì§€ í™•ì¸
        if mail_id in self.eval_df["mail_id"].values:
            existing = self.eval_df[self.eval_df["mail_id"] == mail_id]
            if existing.iloc[:, 2:-5].notna().all(axis=None):
                return

        # metric ê³„ì‚°
        (entropy_val, diversity_val, p_val, acc_val, _, _, c_v) = MetricCalculator.compute_metrics(
            results, ground_truth
        )

        new_row = pd.DataFrame(
            [[mail_id, ground_truth] + results + [entropy_val, diversity_val, p_val, acc_val, c_v]],
            columns=self.columns,
        )
        self.eval_df = pd.concat([self.eval_df, new_row], ignore_index=True)
        self.eval_df.to_csv(self.csv_file_path, index=False)

    def print_df(self):
        """
        ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥:
          1) Correctness(ì¹´í…Œê³ ë¦¬ë³„ 2Ã—2 í˜¼ë™í–‰ë ¬, ì „ì²´/ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„, GT vs Inference ìƒê´€ê³„ìˆ˜)
          2) Consistency(Ground Truth ë³„ ìš”ì•½ëœ ë©”íŠ¸ë¦­)
        """
        if self.eval_df.empty:
            print("âš ï¸ ì €ì¥ëœ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        self._print_correctness()

        self._print_consistency()

    def _print_correctness(self):
        """
        Correctness:
         - ì¹´í…Œê³ ë¦¬ë³„(ground_truthë³„) 2Ã—2 í˜¼ë™í–‰ë ¬ ì‹œê°í™”
         - ì „ì²´ ì •í™•ë„, ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„
         - Ground Truth vs Inference_i ìƒê´€ê³„ìˆ˜(íšŒì°¨ë³„)
        """
        # (1) ì „ì²´ ì •í™•ë„
        overall_acc = MetricCalculator.compute_overall_accuracy(self.eval_df, self.inference_count)

        # (2) ì¹´í…Œê³ ë¦¬ë³„ 2Ã—2 í˜¼ë™í–‰ë ¬ & ì •í™•ë„
        cat_accuracy_dict = MetricCalculator.compute_category_accuracy_2x2(self.eval_df, self.inference_count)

        print("\nCorrectness")
        print(f"ğŸ¯ ì „ì²´ ì •í™•ë„: {overall_acc:.4f}")
        for gt, acc in cat_accuracy_dict.items():
            print(f"ğŸ¯ {gt} ì •í™•ë„: {acc:.4f}")

        print()

    def _print_consistency(self):
        """
        Consistency:
         - Ground Truth ë³„ Entropy, Diversity Index, Chi-Square p-value, Accuracy, Cramer's V
        """
        summary_df = MetricCalculator.group_consistency_metrics(self.eval_df, self.inference_count)
        print("Consistency")
        print("ğŸ“Š Ground Truth ë³„ ìš”ì•½ëœ í‰ê°€ ë©”íŠ¸ë¦­")
        print(summary_df)
