{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result í‰ê°€ ìŠ¤í¬ë¦½íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_SUMMARY_CSV = \"evaluation/data/generated_summary.csv\"\n",
    "GENERATED_CATEGORY_CSV = \"evaluation/data/generated_category.csv\"\n",
    "GENERATED_REPORT_CSV = \"evaluation/data/generated_report.csv\"\n",
    "\n",
    "REFERNECE_CSV = \"evaluation/data/reference.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import ë° í™˜ê²½ ì£¼ì…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agents.classification.classification_type import ClassificationType\n",
    "from evaluation.classification.dataframe_manager import DataFrameManager\n",
    "from evaluation.evaluation_summary import evaluate_summary\n",
    "from evaluation.gpt_eval import calculate_g_eval\n",
    "from evaluation.result_printer import print_evaluation_results\n",
    "from utils.configuration import Config\n",
    "\n",
    "load_dotenv()\n",
    "Config.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(reference_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "      <th>category</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>*ì§€ì†ê°€ëŠ¥ì›ì´ ì¶”ì²œí•˜ëŠ” 2025-1 ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„ !*\\n\\nESG? ì§€ì†ê°€...</td>\n",
       "      <td>[ì§€ì†ê°€ëŠ¥ì›] ì§€ì†ê°€ëŠ¥ì›ì´ ì¶”ì²œí•˜ëŠ” 2025-1 ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„ !</td>\n",
       "      <td>other</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n</td>\n",
       "      <td>ICTëª…í’ˆì¸ì¬ì–‘ì„±ì‚¬ì—…ë‹¨ ë‰´ìŠ¤ë ˆí„° ê²¨ìš¸í˜¸ë¥¼ ë³´ë‚´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>academic</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”,\\n\\n\\n2024ë…„ ì—…ì í‰ê°€ë¥¼ ìœ„í•´ ì‹¤ì  ì—…ë°ì´íŠ¸ ìš”ì²­ì„ ë“œë¦½ë‹ˆë‹¤. ì´...</td>\n",
       "      <td>2024ë…„ ì—…ì í‰ê°€ë¥¼ ìœ„í•œ ì—°êµ¬ì‹¤ì  ì—…ë°ì´íŠ¸ ìš”ì²­ì˜ ê±´ (~2ì›” 7ì¼)</td>\n",
       "      <td>academic</td>\n",
       "      <td>action needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e334940f6bad0</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”\\nì¹œí™˜ê²½ ë””ì§€í„¸ ì •ë³´ê³¼í•™ êµìœ¡ì—°êµ¬ë‹¨ í•¨ì´ì—´ì…ë‹ˆë‹¤.\\n\\nBK21 ëŒ€í•™ì›í˜...</td>\n",
       "      <td>[BK] 2025ë…„ 2ì›” 7ì¼(ê¸ˆ) BK21 ëŒ€í•™ì›í˜ì‹ ì‚¬ì—… ì˜ì–´ë…¼ë¬¸ì‘ì„±ë²• ì›Œí¬ìˆ ì•ˆ...</td>\n",
       "      <td>academic</td>\n",
       "      <td>action needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e325d62686180</td>\n",
       "      <td>Hi there,\\n\\nWe charged $5.20 to your credit c...</td>\n",
       "      <td>Your OpenAI API account has been funded</td>\n",
       "      <td>other</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               body  \\\n",
       "0  194e90265a3c53fe  *ì§€ì†ê°€ëŠ¥ì›ì´ ì¶”ì²œí•˜ëŠ” 2025-1 ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„ !*\\n\\nESG? ì§€ì†ê°€...   \n",
       "1  194e343333e5ff27                         \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   \n",
       "2  194e34039181a3c0  ì•ˆë…•í•˜ì„¸ìš”,\\n\\n\\n2024ë…„ ì—…ì í‰ê°€ë¥¼ ìœ„í•´ ì‹¤ì  ì—…ë°ì´íŠ¸ ìš”ì²­ì„ ë“œë¦½ë‹ˆë‹¤. ì´...   \n",
       "3  194e334940f6bad0  ì•ˆë…•í•˜ì„¸ìš”\\nì¹œí™˜ê²½ ë””ì§€í„¸ ì •ë³´ê³¼í•™ êµìœ¡ì—°êµ¬ë‹¨ í•¨ì´ì—´ì…ë‹ˆë‹¤.\\n\\nBK21 ëŒ€í•™ì›í˜...   \n",
       "4  194e325d62686180  Hi there,\\n\\nWe charged $5.20 to your credit c...   \n",
       "\n",
       "                                             subject  category         action  \n",
       "0           [ì§€ì†ê°€ëŠ¥ì›] ì§€ì†ê°€ëŠ¥ì›ì´ ì¶”ì²œí•˜ëŠ” 2025-1 ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„ !     other      read only  \n",
       "1                    ICTëª…í’ˆì¸ì¬ì–‘ì„±ì‚¬ì—…ë‹¨ ë‰´ìŠ¤ë ˆí„° ê²¨ìš¸í˜¸ë¥¼ ë³´ë‚´ ë“œë¦½ë‹ˆë‹¤.  academic      read only  \n",
       "2            2024ë…„ ì—…ì í‰ê°€ë¥¼ ìœ„í•œ ì—°êµ¬ì‹¤ì  ì—…ë°ì´íŠ¸ ìš”ì²­ì˜ ê±´ (~2ì›” 7ì¼)  academic  action needed  \n",
       "3  [BK] 2025ë…„ 2ì›” 7ì¼(ê¸ˆ) BK21 ëŒ€í•™ì›í˜ì‹ ì‚¬ì—… ì˜ì–´ë…¼ë¬¸ì‘ì„±ë²• ì›Œí¬ìˆ ì•ˆ...  academic  action needed  \n",
       "4            Your OpenAI API account has been funded     other      read only  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_df = pd.read_csv(REFERNECE_CSV)\n",
    "print(\"len(reference_df):\", len(reference_df))\n",
    "reference_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary í‰ê°€\n",
    "\n",
    "1. ìš”ì•½ì „ ì›ë¬¸(ê³ ì •)\n",
    "2. REFERENCE(ê³ ì •)\n",
    "3. ìƒì„± ìš”ì•½ë¬¸\n",
    "\n",
    "Return\n",
    "ROUGE, BERT SCORE, G-EVAL(with summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_summary_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194eaa45baa51ec0</td>\n",
       "      <td>ì¼ì–´ë‚˜ ìŠ¤í„°ë””í•´ì•¼ì§€ ì—…ë°ì´íŠ¸: ì•ˆí˜œì¤€ ì •ë¦¬ - GPT-2ì˜ í•™ìŠµ ë°ì´í„°ì™€ ìš©ëŸ‰ì€ B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194eaa3c5169e920</td>\n",
       "      <td>ì¼ì–´ë‚˜ ìŠ¤í„°ë””í•´ì•¼ì§€ ì—…ë°ì´íŠ¸: LLaMa-1 ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì„±ëŠ¥ ê²€í† . LLaMa-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>ì§€ì†ê°€ëŠ¥ì› ë§í¬ë¥¼ í†µí•´ 2025-1 ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„  í™•ì¸, ê²Œì‹œë¬¼ ë§í¬ ë°”ë¡œê°€ê¸°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>ICTëª…í’ˆì¸ì¬ì–‘ì„±ì‚¬ì—…ë‹¨ ë‰´ìŠ¤ë ˆí„° ê²¨ìš¸í˜¸ ë°œì†¡, 2025ë…„ 2ì›” 8ì¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>2024ë…„ ì—…ì í‰ê°€ë¥¼ ìœ„í•œ ì—°êµ¬ì‹¤ì  ì—…ë°ì´íŠ¸ ìš”ì²­, 2024ë…„ ì‹¤ì  ì¶”ê°€ ì—…ë°ì´íŠ¸,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                            summary\n",
       "0  194eaa45baa51ec0  ì¼ì–´ë‚˜ ìŠ¤í„°ë””í•´ì•¼ì§€ ì—…ë°ì´íŠ¸: ì•ˆí˜œì¤€ ì •ë¦¬ - GPT-2ì˜ í•™ìŠµ ë°ì´í„°ì™€ ìš©ëŸ‰ì€ B...\n",
       "1  194eaa3c5169e920  ì¼ì–´ë‚˜ ìŠ¤í„°ë””í•´ì•¼ì§€ ì—…ë°ì´íŠ¸: LLaMa-1 ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì„±ëŠ¥ ê²€í† . LLaMa-...\n",
       "2  194e90265a3c53fe   ì§€ì†ê°€ëŠ¥ì› ë§í¬ë¥¼ í†µí•´ 2025-1 ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„  í™•ì¸, ê²Œì‹œë¬¼ ë§í¬ ë°”ë¡œê°€ê¸°\n",
       "3  194e343333e5ff27              ICTëª…í’ˆì¸ì¬ì–‘ì„±ì‚¬ì—…ë‹¨ ë‰´ìŠ¤ë ˆí„° ê²¨ìš¸í˜¸ ë°œì†¡, 2025ë…„ 2ì›” 8ì¼\n",
       "4  194e34039181a3c0  2024ë…„ ì—…ì í‰ê°€ë¥¼ ìœ„í•œ ì—°êµ¬ì‹¤ì  ì—…ë°ì´íŠ¸ ìš”ì²­, 2024ë…„ ì‹¤ì  ì¶”ê°€ ì—…ë°ì´íŠ¸,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summary_df = pd.read_csv(GENERATED_SUMMARY_CSV)\n",
    "print(\"len(generated_summary_df):\", len(generated_summary_df))\n",
    "generated_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "g-eval start with **gpt-4o-mini**\n",
      "\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=1\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 5\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=- Consistency: 2\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=2\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=3\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=3\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=- Consistency: 4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=2\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 3\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 5\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=2\n",
      "[G-EVAL] aspect=coherence, gpt_text=3\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=3\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=5\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=3\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n"
     ]
    }
   ],
   "source": [
    "source_texts = reference_df[\"body\"].tolist()\n",
    "report_texts = generated_summary_df[\"summary\"].tolist()\n",
    "reference_texts = reference_df[\"subject\"].tolist()\n",
    "\n",
    "summary_results = evaluate_summary(source_texts, report_texts, reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SUMMARY Evaluation Results =====\n",
      "\n",
      "--- Summary Sample 1 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8040, R:0.8733, F:0.8372\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=2.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 2 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.7661, R:0.8794, F:0.8189\n",
      "[G-EVAL] consistency=4.0000, coherence=5.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 3 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8839, R:0.8745, F:0.8792\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=2.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 4 ---\n",
      "[ROUGE] R1=(P:0.5000,R:0.4000,F:0.4444), R2=(P:0.3333,R:0.2500,F:0.2857), RL=(P:0.5000,R:0.4000,F:0.4444)\n",
      "[BERT] P:0.8825, R:0.8343, F:0.8578\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=3.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 5 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.5037, R:0.5913, F:0.5440\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=3.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 6 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.4727, R:0.5746, F:0.5187\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=2.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 7 ---\n",
      "[ROUGE] R1=(P:0.5000,R:0.2857,F:0.3636), R2=(P:0.3333,R:0.1667,F:0.2222), RL=(P:0.5000,R:0.2857,F:0.3636)\n",
      "[BERT] P:0.5074, R:0.6852, F:0.5831\n",
      "[G-EVAL] consistency=2.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 8 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8188, R:0.8441, F:0.8312\n",
      "[G-EVAL] consistency=1.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 9 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8144, R:0.8845, F:0.8480\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=3.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 10 ---\n",
      "[ROUGE] R1=(P:0.0714,R:1.0000,F:0.1333), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0714,R:1.0000,F:0.1333)\n",
      "[BERT] P:0.7915, R:0.8920, F:0.8388\n",
      "[G-EVAL] consistency=2.0000, coherence=4.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 11 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8493, R:0.9401, F:0.8924\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 12 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8493, R:0.9401, F:0.8924\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 13 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8391, R:0.9400, F:0.8867\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 14 ---\n",
      "[ROUGE] R1=(P:0.2857,R:1.0000,F:0.4444), R2=(P:0.1667,R:1.0000,F:0.2857), RL=(P:0.2857,R:1.0000,F:0.4444)\n",
      "[BERT] P:0.8686, R:0.9170, F:0.8921\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 15 ---\n",
      "[ROUGE] R1=(P:1.0000,R:1.0000,F:1.0000), R2=(P:0.5000,R:0.5000,F:0.5000), RL=(P:0.6667,R:0.6667,F:0.6667)\n",
      "[BERT] P:0.9056, R:0.9193, F:0.9124\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 16 ---\n",
      "[ROUGE] R1=(P:0.3333,R:1.0000,F:0.5000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.3333,R:1.0000,F:0.5000)\n",
      "[BERT] P:0.8858, R:0.9299, F:0.9073\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 17 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8994, R:0.9256, F:0.9123\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 18 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8884, R:0.9099, F:0.8990\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 19 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8914, R:0.9097, F:0.9005\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 20 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8824, R:0.9002, F:0.8912\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 21 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9232, R:0.9223, F:0.9227\n",
      "[G-EVAL] consistency=3.0000, coherence=2.0000, fluency=2.0000, relevance=3.0000\n",
      "\n",
      "--- Summary Sample 22 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8635, R:0.8960, F:0.8795\n",
      "[G-EVAL] consistency=4.0000, coherence=4.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 23 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9149, R:0.9184, F:0.9166\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 24 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9013, R:0.8784, F:0.8897\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 25 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9217, R:0.9377, F:0.9296\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 26 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8612, R:0.9022, F:0.8812\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 27 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8923, R:0.8953, F:0.8938\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 28 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8906, R:0.8880, F:0.8893\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 29 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8835, R:0.9221, F:0.9024\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 30 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9290, R:0.9099, F:0.9194\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 31 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8819, R:0.9092, F:0.8953\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 32 ---\n",
      "[ROUGE] R1=(P:0.1818,R:0.2500,F:0.2105), R2=(P:0.1000,R:0.1429,F:0.1176), RL=(P:0.1818,R:0.2500,F:0.2105)\n",
      "[BERT] P:0.5831, R:0.7130, F:0.6416\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 33 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8141, R:0.8469, F:0.8302\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 34 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8041, R:0.8957, F:0.8474\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 35 ---\n",
      "[ROUGE] R1=(P:0.0455,R:1.0000,F:0.0870), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0455,R:1.0000,F:0.0870)\n",
      "[BERT] P:0.7647, R:0.8941, F:0.8244\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 36 ---\n",
      "[ROUGE] R1=(P:1.0000,R:1.0000,F:1.0000), R2=(P:1.0000,R:1.0000,F:1.0000), RL=(P:1.0000,R:1.0000,F:1.0000)\n",
      "[BERT] P:0.9429, R:0.9232, F:0.9330\n",
      "[G-EVAL] consistency=2.0000, coherence=2.0000, fluency=3.0000, relevance=3.0000\n",
      "\n",
      "--- Summary Sample 37 ---\n",
      "[ROUGE] R1=(P:0.1739,R:0.5000,F:0.2581), R2=(P:0.0909,R:0.2857,F:0.1379), RL=(P:0.1739,R:0.5000,F:0.2581)\n",
      "[BERT] P:0.8064, R:0.8366, F:0.8212\n",
      "[G-EVAL] consistency=4.0000, coherence=5.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 38 ---\n",
      "[ROUGE] R1=(P:0.2222,R:1.0000,F:0.3636), R2=(P:0.1250,R:1.0000,F:0.2222), RL=(P:0.2222,R:1.0000,F:0.3636)\n",
      "[BERT] P:0.8467, R:0.9225, F:0.8830\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 39 ---\n",
      "[ROUGE] R1=(P:0.3333,R:1.0000,F:0.5000), R2=(P:0.2000,R:1.0000,F:0.3333), RL=(P:0.3333,R:1.0000,F:0.5000)\n",
      "[BERT] P:0.8281, R:0.8786, F:0.8526\n",
      "[G-EVAL] consistency=2.0000, coherence=3.0000, fluency=3.0000, relevance=3.0000\n",
      "\n",
      "--- Summary Sample 40 ---\n",
      "[ROUGE] R1=(P:0.2000,R:1.0000,F:0.3333), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.2000,R:1.0000,F:0.3333)\n",
      "[BERT] P:0.8941, R:0.9229, F:0.9082\n",
      "[G-EVAL] consistency=5.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 41 ---\n",
      "[ROUGE] R1=(P:1.0000,R:1.0000,F:1.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:1.0000,R:1.0000,F:1.0000)\n",
      "[BERT] P:0.9115, R:0.9440, F:0.9274\n",
      "[G-EVAL] consistency=4.0000, coherence=4.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 42 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8408, R:0.9543, F:0.8939\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 43 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8732, R:0.9286, F:0.9000\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 44 ---\n",
      "[ROUGE] R1=(P:1.0000,R:0.5000,F:0.6667), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:1.0000,R:0.5000,F:0.6667)\n",
      "[BERT] P:0.9057, R:0.9219, F:0.9137\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 45 ---\n",
      "[ROUGE] R1=(P:0.2143,R:0.6000,F:0.3158), R2=(P:0.1538,R:0.5000,F:0.2353), RL=(P:0.2143,R:0.6000,F:0.3158)\n",
      "[BERT] P:0.5881, R:0.8369, F:0.6907\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 46 ---\n",
      "[ROUGE] R1=(P:0.2500,R:0.6000,F:0.3529), R2=(P:0.1739,R:0.4444,F:0.2500), RL=(P:0.2500,R:0.6000,F:0.3529)\n",
      "[BERT] P:0.5492, R:0.8019, F:0.6519\n",
      "[G-EVAL] consistency=5.0000, coherence=5.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 47 ---\n",
      "[ROUGE] R1=(P:0.2083,R:1.0000,F:0.3448), R2=(P:0.1304,R:0.7500,F:0.2222), RL=(P:0.2083,R:1.0000,F:0.3448)\n",
      "[BERT] P:0.7997, R:0.8637, F:0.8305\n",
      "[G-EVAL] consistency=4.0000, coherence=4.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 48 ---\n",
      "[ROUGE] R1=(P:0.6250,R:0.8333,F:0.7143), R2=(P:0.4286,R:0.6000,F:0.5000), RL=(P:0.6250,R:0.8333,F:0.7143)\n",
      "[BERT] P:0.8688, R:0.9227, F:0.8949\n",
      "[G-EVAL] consistency=3.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "===== Averages =====\n",
      "\n",
      "[ROUGE Avg]\n",
      "  ROUGE-1: P=0.1697, R=0.1592, F1=0.3049\n",
      "  ROUGE-2: P=0.0000, R=0.0000, F1=0.0000\n",
      "  ROUGE-L: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "[BERT Avg]\n",
      "  Precision: 0.8227, Recall: 0.8782, F1: 0.8481\n",
      "\n",
      "[G-EVAL Avg]\n",
      "  consistency=3.4792, coherence=2.7083, fluency=2.7292, relevance=3.8542\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(summary_results, eval_type=\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¶„ë¥˜ í‰ê°€\n",
    "\n",
    "1. ë¼ë²¨ Ground truth(ê³ ì •)\n",
    "2. ì—¬ëŸ¬ë²ˆ ê²°ê³¼(Në²ˆ) ê°€ì§€ê³  ìˆëŠ” ë¦¬ìŠ¤íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_category_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194eaa45baa51ec0</td>\n",
       "      <td>['academic', 'academic']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194eaa3c5169e920</td>\n",
       "      <td>['academic', 'academic']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>['other', 'other']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>['other', 'other']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>['administration', 'administration']</td>\n",
       "      <td>['action needed', 'action needed']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                            categories  \\\n",
       "0  194eaa45baa51ec0              ['academic', 'academic']   \n",
       "1  194eaa3c5169e920              ['academic', 'academic']   \n",
       "2  194e90265a3c53fe                    ['other', 'other']   \n",
       "3  194e343333e5ff27                    ['other', 'other']   \n",
       "4  194e34039181a3c0  ['administration', 'administration']   \n",
       "\n",
       "                              actions  \n",
       "0          ['read only', 'read only']  \n",
       "1          ['read only', 'read only']  \n",
       "2          ['read only', 'read only']  \n",
       "3          ['read only', 'read only']  \n",
       "4  ['action needed', 'action needed']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_category_df = pd.read_csv(GENERATED_CATEGORY_CSV)\n",
    "print(\"len(generated_category_df):\", len(generated_category_df))\n",
    "generated_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: evaluation/classification/figure/academic_confusion_matrix.png\n",
      "âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: evaluation/classification/figure/administration_confusion_matrix.png\n",
      "âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: evaluation/classification/figure/other_confusion_matrix.png\n",
      "\n",
      "Correctness\n",
      "ğŸ¯ ì „ì²´ ì •í™•ë„: 0.6875\n",
      "ğŸ¯ academic ì •í™•ë„: 0.7500\n",
      "ğŸ¯ administration ì •í™•ë„: 0.8542\n",
      "ğŸ¯ other ì •í™•ë„: 0.7708\n",
      "\n",
      "Consistency\n",
      "ğŸ“Š Ground Truth ë³„ ìš”ì•½ëœ í‰ê°€ ë©”íŠ¸ë¦­\n",
      "     Ground Truth   Entropy  Diversity Index  Chi-Square p-value  Accuracy  \\\n",
      "0        academic  0.876006         0.107143                   1  0.571429   \n",
      "1  administration  0.758937         0.107143                   1  0.714286   \n",
      "2           other  0.730588         0.075000                   1  0.750000   \n",
      "\n",
      "   Cramer's V  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "\n",
      "=== Overall Multiclass Confusion Matrix ===\n",
      "Labels: ['academic', 'administration', 'other']\n",
      "[[16  2 10]\n",
      " [ 6 20  2]\n",
      " [ 6  4 30]]\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_df_manager = DataFrameManager(Config.config[\"classification\"][\"inference\"], ClassificationType.CATEGORY)\n",
    "for index, row in generated_category_df.iterrows():\n",
    "    category_df_manager.update_eval_df(\n",
    "        row[\"id\"], ast.literal_eval(row[\"categories\"]), reference_df.loc[index, \"category\"]\n",
    "    )\n",
    "\n",
    "category_df_manager.print_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: evaluation/classification/figure/action needed_confusion_matrix.png\n",
      "âœ… Confusion Matrix ì €ì¥ ì™„ë£Œ: evaluation/classification/figure/read only_confusion_matrix.png\n",
      "\n",
      "Correctness\n",
      "ğŸ¯ ì „ì²´ ì •í™•ë„: 0.7500\n",
      "ğŸ¯ action needed ì •í™•ë„: 0.7500\n",
      "ğŸ¯ read only ì •í™•ë„: 0.7500\n",
      "\n",
      "Consistency\n",
      "ğŸ“Š Ground Truth ë³„ ìš”ì•½ëœ í‰ê°€ ë©”íŠ¸ë¦­\n",
      "    Ground Truth   Entropy  Diversity Index  Chi-Square p-value  Accuracy  \\\n",
      "0  action needed  0.545595         0.058824                   1  0.764706   \n",
      "1      read only  0.571023         0.032258                   1  0.741935   \n",
      "\n",
      "   Cramer's V  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "\n",
      "=== Overall Multiclass Confusion Matrix ===\n",
      "Labels: ['action needed', 'read only']\n",
      "[[26  8]\n",
      " [16 46]]\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action_df_manager = DataFrameManager(Config.config[\"classification\"][\"inference\"], ClassificationType.ACTION)\n",
    "for index, row in generated_category_df.iterrows():\n",
    "    action_df_manager.update_eval_df(row[\"id\"], ast.literal_eval(row[\"actions\"]), reference_df.loc[index, \"action\"])\n",
    "\n",
    "action_df_manager.print_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìµœì¢… report í‰ê°€\n",
    "\n",
    "1. ìš”ì•½ì „ ì›ë¬¸(ë©”ì¼ ìš”ì•½ë¬¸ concat)\n",
    "2. ìƒì„± ìš”ì•½ë¬¸\n",
    "\n",
    "Return\n",
    "G-EVAL(with final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_report_df): 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì¼ì–´ë‚˜ ìŠ¤í„°ë””í•´ì•¼ì§€ ì—…ë°ì´íŠ¸: ì•ˆí˜œì¤€ ì •ë¦¬ - GPT-2ì˜ í•™ìŠµ ë°ì´í„°ì™€ ìš©ëŸ‰ì€ B...</td>\n",
       "      <td>ë©”ì¼ ë‚´ìš©ì€ LLaMa-1 ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì„±ëŠ¥ ê²€í† , ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„  í™•ì¸,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  ì¼ì–´ë‚˜ ìŠ¤í„°ë””í•´ì•¼ì§€ ì—…ë°ì´íŠ¸: ì•ˆí˜œì¤€ ì •ë¦¬ - GPT-2ì˜ í•™ìŠµ ë°ì´í„°ì™€ ìš©ëŸ‰ì€ B...   \n",
       "\n",
       "                                              report  \n",
       "0  ë©”ì¼ ë‚´ìš©ì€ LLaMa-1 ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì„±ëŠ¥ ê²€í† , ì§€ì†ê°€ëŠ¥ êµê³¼ëª© 25ì„  í™•ì¸,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_report_df = pd.read_csv(GENERATED_REPORT_CSV)\n",
    "print(\"len(generated_report_df):\", len(generated_report_df))\n",
    "generated_report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "g-eval start with **gpt-4o-mini**\n",
      "\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"g-eval\"] = calculate_g_eval(\n",
    "    source_texts=generated_report_df[\"source\"].tolist(),\n",
    "    generated_texts=generated_report_df[\"report\"].tolist(),\n",
    "    eval_type=\"report\",\n",
    "    model_name=Config.config[\"summary\"][\"g_eval\"][\"openai_model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== REPORT Evaluation Results =====\n",
      "\n",
      "--- Report Sample 1 ---\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "===== Averages =====\n",
      "\n",
      "[G-EVAL Avg]\n",
      "  consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(results, eval_type=\"report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
