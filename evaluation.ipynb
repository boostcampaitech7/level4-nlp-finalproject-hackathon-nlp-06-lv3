{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 평가 스크립트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_SUMMARY_CSV = \"evaluation/data/generated_summary.csv\"\n",
    "GENERATED_CATEGORY_CSV = \"evaluation/data/generated_category.csv\"\n",
    "GENERATED_REPORT_CSV = \"evaluation/data/generated_report.csv\"\n",
    "\n",
    "REFERNECE_CSV = \"evaluation/data/reference.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import 및 환경 주입\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agents.classification.classification_type import ClassificationType\n",
    "from evaluation.classification.dataframe_manager import DataFrameManager\n",
    "from evaluation.evaluation_summary import evaluate_summary\n",
    "from evaluation.gpt_eval import calculate_g_eval\n",
    "from evaluation.result_printer import print_evaluation_results\n",
    "from utils.configuration import Config\n",
    "\n",
    "load_dotenv()\n",
    "Config.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(reference_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "      <th>category</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>*지속가능원이 추천하는 2025-1 지속가능 교과목 25선!*\\n\\nESG? 지속가...</td>\n",
       "      <td>[지속가능원] 지속가능원이 추천하는 2025-1 지속가능 교과목 25선!</td>\n",
       "      <td>other</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n</td>\n",
       "      <td>ICT명품인재양성사업단 뉴스레터 겨울호를 보내 드립니다.</td>\n",
       "      <td>academic</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>안녕하세요,\\n\\n\\n2024년 업적평가를 위해 실적 업데이트 요청을 드립니다. 이...</td>\n",
       "      <td>2024년 업적평가를 위한 연구실적 업데이트 요청의 건 (~2월 7일)</td>\n",
       "      <td>academic</td>\n",
       "      <td>action needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e334940f6bad0</td>\n",
       "      <td>안녕하세요\\n친환경 디지털 정보과학 교육연구단 함이열입니다.\\n\\nBK21 대학원혁...</td>\n",
       "      <td>[BK] 2025년 2월 7일(금) BK21 대학원혁신사업 영어논문작성법 워크숍 안...</td>\n",
       "      <td>academic</td>\n",
       "      <td>action needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e325d62686180</td>\n",
       "      <td>Hi there,\\n\\nWe charged $5.20 to your credit c...</td>\n",
       "      <td>Your OpenAI API account has been funded</td>\n",
       "      <td>other</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               body  \\\n",
       "0  194e90265a3c53fe  *지속가능원이 추천하는 2025-1 지속가능 교과목 25선!*\\n\\nESG? 지속가...   \n",
       "1  194e343333e5ff27                         \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   \n",
       "2  194e34039181a3c0  안녕하세요,\\n\\n\\n2024년 업적평가를 위해 실적 업데이트 요청을 드립니다. 이...   \n",
       "3  194e334940f6bad0  안녕하세요\\n친환경 디지털 정보과학 교육연구단 함이열입니다.\\n\\nBK21 대학원혁...   \n",
       "4  194e325d62686180  Hi there,\\n\\nWe charged $5.20 to your credit c...   \n",
       "\n",
       "                                             subject  category         action  \n",
       "0           [지속가능원] 지속가능원이 추천하는 2025-1 지속가능 교과목 25선!     other      read only  \n",
       "1                    ICT명품인재양성사업단 뉴스레터 겨울호를 보내 드립니다.  academic      read only  \n",
       "2            2024년 업적평가를 위한 연구실적 업데이트 요청의 건 (~2월 7일)  academic  action needed  \n",
       "3  [BK] 2025년 2월 7일(금) BK21 대학원혁신사업 영어논문작성법 워크숍 안...  academic  action needed  \n",
       "4            Your OpenAI API account has been funded     other      read only  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_df = pd.read_csv(REFERNECE_CSV)\n",
    "print(\"len(reference_df):\", len(reference_df))\n",
    "reference_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary 평가\n",
    "\n",
    "1. 요약전 원문(고정)\n",
    "2. REFERENCE(고정)\n",
    "3. 생성 요약문\n",
    "\n",
    "Return\n",
    "ROUGE, BERT SCORE, G-EVAL(with summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_summary_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194eaa45baa51ec0</td>\n",
       "      <td>일어나 스터디해야지 업데이트: 안혜준 정리 - GPT-2의 학습 데이터와 용량은 B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194eaa3c5169e920</td>\n",
       "      <td>일어나 스터디해야지 업데이트: LLaMa-1 모델의 특징과 성능 검토. LLaMa-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>지속가능원 링크를 통해 2025-1 지속가능 교과목 25선 확인, 게시물 링크 바로가기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>ICT명품인재양성사업단 뉴스레터 겨울호 발송, 2025년 2월 8일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>2024년 업적평가를 위한 연구실적 업데이트 요청, 2024년 실적 추가 업데이트,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                            summary\n",
       "0  194eaa45baa51ec0  일어나 스터디해야지 업데이트: 안혜준 정리 - GPT-2의 학습 데이터와 용량은 B...\n",
       "1  194eaa3c5169e920  일어나 스터디해야지 업데이트: LLaMa-1 모델의 특징과 성능 검토. LLaMa-...\n",
       "2  194e90265a3c53fe   지속가능원 링크를 통해 2025-1 지속가능 교과목 25선 확인, 게시물 링크 바로가기\n",
       "3  194e343333e5ff27              ICT명품인재양성사업단 뉴스레터 겨울호 발송, 2025년 2월 8일\n",
       "4  194e34039181a3c0  2024년 업적평가를 위한 연구실적 업데이트 요청, 2024년 실적 추가 업데이트,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summary_df = pd.read_csv(GENERATED_SUMMARY_CSV)\n",
    "print(\"len(generated_summary_df):\", len(generated_summary_df))\n",
    "generated_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "g-eval start with **gpt-4o-mini**\n",
      "\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=1\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 5\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=- Consistency: 2\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=1\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 1\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 1\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=2\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=3\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=3\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=- Consistency: 4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=- Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=- Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=2\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=Relevance: 3\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 5\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=2\n",
      "[G-EVAL] aspect=coherence, gpt_text=3\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=3\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=5\n",
      "[G-EVAL] aspect=coherence, gpt_text=5\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=5\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=4\n",
      "[G-EVAL] aspect=fluency, gpt_text=Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=3\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 3\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 3\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n"
     ]
    }
   ],
   "source": [
    "source_texts = reference_df[\"body\"].tolist()\n",
    "report_texts = generated_summary_df[\"summary\"].tolist()\n",
    "reference_texts = reference_df[\"subject\"].tolist()\n",
    "\n",
    "summary_results = evaluate_summary(source_texts, report_texts, reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SUMMARY Evaluation Results =====\n",
      "\n",
      "--- Summary Sample 1 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8040, R:0.8733, F:0.8372\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=2.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 2 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.7661, R:0.8794, F:0.8189\n",
      "[G-EVAL] consistency=4.0000, coherence=5.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 3 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8839, R:0.8745, F:0.8792\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=2.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 4 ---\n",
      "[ROUGE] R1=(P:0.5000,R:0.4000,F:0.4444), R2=(P:0.3333,R:0.2500,F:0.2857), RL=(P:0.5000,R:0.4000,F:0.4444)\n",
      "[BERT] P:0.8825, R:0.8343, F:0.8578\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=3.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 5 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.5037, R:0.5913, F:0.5440\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=3.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 6 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.4727, R:0.5746, F:0.5187\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=2.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 7 ---\n",
      "[ROUGE] R1=(P:0.5000,R:0.2857,F:0.3636), R2=(P:0.3333,R:0.1667,F:0.2222), RL=(P:0.5000,R:0.2857,F:0.3636)\n",
      "[BERT] P:0.5074, R:0.6852, F:0.5831\n",
      "[G-EVAL] consistency=2.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 8 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8188, R:0.8441, F:0.8312\n",
      "[G-EVAL] consistency=1.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 9 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8144, R:0.8845, F:0.8480\n",
      "[G-EVAL] consistency=1.0000, coherence=1.0000, fluency=3.0000, relevance=1.0000\n",
      "\n",
      "--- Summary Sample 10 ---\n",
      "[ROUGE] R1=(P:0.0714,R:1.0000,F:0.1333), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0714,R:1.0000,F:0.1333)\n",
      "[BERT] P:0.7915, R:0.8920, F:0.8388\n",
      "[G-EVAL] consistency=2.0000, coherence=4.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 11 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8493, R:0.9401, F:0.8924\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 12 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8493, R:0.9401, F:0.8924\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 13 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8391, R:0.9400, F:0.8867\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 14 ---\n",
      "[ROUGE] R1=(P:0.2857,R:1.0000,F:0.4444), R2=(P:0.1667,R:1.0000,F:0.2857), RL=(P:0.2857,R:1.0000,F:0.4444)\n",
      "[BERT] P:0.8686, R:0.9170, F:0.8921\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 15 ---\n",
      "[ROUGE] R1=(P:1.0000,R:1.0000,F:1.0000), R2=(P:0.5000,R:0.5000,F:0.5000), RL=(P:0.6667,R:0.6667,F:0.6667)\n",
      "[BERT] P:0.9056, R:0.9193, F:0.9124\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 16 ---\n",
      "[ROUGE] R1=(P:0.3333,R:1.0000,F:0.5000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.3333,R:1.0000,F:0.5000)\n",
      "[BERT] P:0.8858, R:0.9299, F:0.9073\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 17 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8994, R:0.9256, F:0.9123\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 18 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8884, R:0.9099, F:0.8990\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 19 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8914, R:0.9097, F:0.9005\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 20 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8824, R:0.9002, F:0.8912\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 21 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9232, R:0.9223, F:0.9227\n",
      "[G-EVAL] consistency=3.0000, coherence=2.0000, fluency=2.0000, relevance=3.0000\n",
      "\n",
      "--- Summary Sample 22 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8635, R:0.8960, F:0.8795\n",
      "[G-EVAL] consistency=4.0000, coherence=4.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 23 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9149, R:0.9184, F:0.9166\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 24 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9013, R:0.8784, F:0.8897\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 25 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9217, R:0.9377, F:0.9296\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 26 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8612, R:0.9022, F:0.8812\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 27 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8923, R:0.8953, F:0.8938\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 28 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8906, R:0.8880, F:0.8893\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 29 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8835, R:0.9221, F:0.9024\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 30 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.9290, R:0.9099, F:0.9194\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 31 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8819, R:0.9092, F:0.8953\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 32 ---\n",
      "[ROUGE] R1=(P:0.1818,R:0.2500,F:0.2105), R2=(P:0.1000,R:0.1429,F:0.1176), RL=(P:0.1818,R:0.2500,F:0.2105)\n",
      "[BERT] P:0.5831, R:0.7130, F:0.6416\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 33 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8141, R:0.8469, F:0.8302\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 34 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8041, R:0.8957, F:0.8474\n",
      "[G-EVAL] consistency=5.0000, coherence=4.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 35 ---\n",
      "[ROUGE] R1=(P:0.0455,R:1.0000,F:0.0870), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0455,R:1.0000,F:0.0870)\n",
      "[BERT] P:0.7647, R:0.8941, F:0.8244\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 36 ---\n",
      "[ROUGE] R1=(P:1.0000,R:1.0000,F:1.0000), R2=(P:1.0000,R:1.0000,F:1.0000), RL=(P:1.0000,R:1.0000,F:1.0000)\n",
      "[BERT] P:0.9429, R:0.9232, F:0.9330\n",
      "[G-EVAL] consistency=2.0000, coherence=2.0000, fluency=3.0000, relevance=3.0000\n",
      "\n",
      "--- Summary Sample 37 ---\n",
      "[ROUGE] R1=(P:0.1739,R:0.5000,F:0.2581), R2=(P:0.0909,R:0.2857,F:0.1379), RL=(P:0.1739,R:0.5000,F:0.2581)\n",
      "[BERT] P:0.8064, R:0.8366, F:0.8212\n",
      "[G-EVAL] consistency=4.0000, coherence=5.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 38 ---\n",
      "[ROUGE] R1=(P:0.2222,R:1.0000,F:0.3636), R2=(P:0.1250,R:1.0000,F:0.2222), RL=(P:0.2222,R:1.0000,F:0.3636)\n",
      "[BERT] P:0.8467, R:0.9225, F:0.8830\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 39 ---\n",
      "[ROUGE] R1=(P:0.3333,R:1.0000,F:0.5000), R2=(P:0.2000,R:1.0000,F:0.3333), RL=(P:0.3333,R:1.0000,F:0.5000)\n",
      "[BERT] P:0.8281, R:0.8786, F:0.8526\n",
      "[G-EVAL] consistency=2.0000, coherence=3.0000, fluency=3.0000, relevance=3.0000\n",
      "\n",
      "--- Summary Sample 40 ---\n",
      "[ROUGE] R1=(P:0.2000,R:1.0000,F:0.3333), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.2000,R:1.0000,F:0.3333)\n",
      "[BERT] P:0.8941, R:0.9229, F:0.9082\n",
      "[G-EVAL] consistency=5.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 41 ---\n",
      "[ROUGE] R1=(P:1.0000,R:1.0000,F:1.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:1.0000,R:1.0000,F:1.0000)\n",
      "[BERT] P:0.9115, R:0.9440, F:0.9274\n",
      "[G-EVAL] consistency=4.0000, coherence=4.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 42 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8408, R:0.9543, F:0.8939\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 43 ---\n",
      "[ROUGE] R1=(P:0.0000,R:0.0000,F:0.0000), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:0.0000,R:0.0000,F:0.0000)\n",
      "[BERT] P:0.8732, R:0.9286, F:0.9000\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 44 ---\n",
      "[ROUGE] R1=(P:1.0000,R:0.5000,F:0.6667), R2=(P:0.0000,R:0.0000,F:0.0000), RL=(P:1.0000,R:0.5000,F:0.6667)\n",
      "[BERT] P:0.9057, R:0.9219, F:0.9137\n",
      "[G-EVAL] consistency=4.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 45 ---\n",
      "[ROUGE] R1=(P:0.2143,R:0.6000,F:0.3158), R2=(P:0.1538,R:0.5000,F:0.2353), RL=(P:0.2143,R:0.6000,F:0.3158)\n",
      "[BERT] P:0.5881, R:0.8369, F:0.6907\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 46 ---\n",
      "[ROUGE] R1=(P:0.2500,R:0.6000,F:0.3529), R2=(P:0.1739,R:0.4444,F:0.2500), RL=(P:0.2500,R:0.6000,F:0.3529)\n",
      "[BERT] P:0.5492, R:0.8019, F:0.6519\n",
      "[G-EVAL] consistency=5.0000, coherence=5.0000, fluency=3.0000, relevance=5.0000\n",
      "\n",
      "--- Summary Sample 47 ---\n",
      "[ROUGE] R1=(P:0.2083,R:1.0000,F:0.3448), R2=(P:0.1304,R:0.7500,F:0.2222), RL=(P:0.2083,R:1.0000,F:0.3448)\n",
      "[BERT] P:0.7997, R:0.8637, F:0.8305\n",
      "[G-EVAL] consistency=4.0000, coherence=4.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "--- Summary Sample 48 ---\n",
      "[ROUGE] R1=(P:0.6250,R:0.8333,F:0.7143), R2=(P:0.4286,R:0.6000,F:0.5000), RL=(P:0.6250,R:0.8333,F:0.7143)\n",
      "[BERT] P:0.8688, R:0.9227, F:0.8949\n",
      "[G-EVAL] consistency=3.0000, coherence=3.0000, fluency=3.0000, relevance=4.0000\n",
      "\n",
      "===== Averages =====\n",
      "\n",
      "[ROUGE Avg]\n",
      "  ROUGE-1: P=0.1697, R=0.1592, F1=0.3049\n",
      "  ROUGE-2: P=0.0000, R=0.0000, F1=0.0000\n",
      "  ROUGE-L: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "[BERT Avg]\n",
      "  Precision: 0.8227, Recall: 0.8782, F1: 0.8481\n",
      "\n",
      "[G-EVAL Avg]\n",
      "  consistency=3.4792, coherence=2.7083, fluency=2.7292, relevance=3.8542\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(summary_results, eval_type=\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 평가\n",
    "\n",
    "1. 라벨 Ground truth(고정)\n",
    "2. 여러번 결과(N번) 가지고 있는 리스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_category_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194eaa45baa51ec0</td>\n",
       "      <td>['academic', 'academic']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194eaa3c5169e920</td>\n",
       "      <td>['academic', 'academic']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>['other', 'other']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>['other', 'other']</td>\n",
       "      <td>['read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>['administration', 'administration']</td>\n",
       "      <td>['action needed', 'action needed']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                            categories  \\\n",
       "0  194eaa45baa51ec0              ['academic', 'academic']   \n",
       "1  194eaa3c5169e920              ['academic', 'academic']   \n",
       "2  194e90265a3c53fe                    ['other', 'other']   \n",
       "3  194e343333e5ff27                    ['other', 'other']   \n",
       "4  194e34039181a3c0  ['administration', 'administration']   \n",
       "\n",
       "                              actions  \n",
       "0          ['read only', 'read only']  \n",
       "1          ['read only', 'read only']  \n",
       "2          ['read only', 'read only']  \n",
       "3          ['read only', 'read only']  \n",
       "4  ['action needed', 'action needed']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_category_df = pd.read_csv(GENERATED_CATEGORY_CSV)\n",
    "print(\"len(generated_category_df):\", len(generated_category_df))\n",
    "generated_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/academic_confusion_matrix.png\n",
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/administration_confusion_matrix.png\n",
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/other_confusion_matrix.png\n",
      "\n",
      "Correctness\n",
      "🎯 전체 정확도: 0.6875\n",
      "🎯 academic 정확도: 0.7500\n",
      "🎯 administration 정확도: 0.8542\n",
      "🎯 other 정확도: 0.7708\n",
      "\n",
      "Consistency\n",
      "📊 Ground Truth 별 요약된 평가 메트릭\n",
      "     Ground Truth   Entropy  Diversity Index  Chi-Square p-value  Accuracy  \\\n",
      "0        academic  0.876006         0.107143                   1  0.571429   \n",
      "1  administration  0.758937         0.107143                   1  0.714286   \n",
      "2           other  0.730588         0.075000                   1  0.750000   \n",
      "\n",
      "   Cramer's V  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "\n",
      "=== Overall Multiclass Confusion Matrix ===\n",
      "Labels: ['academic', 'administration', 'other']\n",
      "[[16  2 10]\n",
      " [ 6 20  2]\n",
      " [ 6  4 30]]\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_df_manager = DataFrameManager(Config.config[\"classification\"][\"inference\"], ClassificationType.CATEGORY)\n",
    "for index, row in generated_category_df.iterrows():\n",
    "    category_df_manager.update_eval_df(\n",
    "        row[\"id\"], ast.literal_eval(row[\"categories\"]), reference_df.loc[index, \"category\"]\n",
    "    )\n",
    "\n",
    "category_df_manager.print_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/action needed_confusion_matrix.png\n",
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/read only_confusion_matrix.png\n",
      "\n",
      "Correctness\n",
      "🎯 전체 정확도: 0.7500\n",
      "🎯 action needed 정확도: 0.7500\n",
      "🎯 read only 정확도: 0.7500\n",
      "\n",
      "Consistency\n",
      "📊 Ground Truth 별 요약된 평가 메트릭\n",
      "    Ground Truth   Entropy  Diversity Index  Chi-Square p-value  Accuracy  \\\n",
      "0  action needed  0.545595         0.058824                   1  0.764706   \n",
      "1      read only  0.571023         0.032258                   1  0.741935   \n",
      "\n",
      "   Cramer's V  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "\n",
      "=== Overall Multiclass Confusion Matrix ===\n",
      "Labels: ['action needed', 'read only']\n",
      "[[26  8]\n",
      " [16 46]]\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action_df_manager = DataFrameManager(Config.config[\"classification\"][\"inference\"], ClassificationType.ACTION)\n",
    "for index, row in generated_category_df.iterrows():\n",
    "    action_df_manager.update_eval_df(row[\"id\"], ast.literal_eval(row[\"actions\"]), reference_df.loc[index, \"action\"])\n",
    "\n",
    "action_df_manager.print_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 report 평가\n",
    "\n",
    "1. 요약전 원문(메일 요약문 concat)\n",
    "2. 생성 요약문\n",
    "\n",
    "Return\n",
    "G-EVAL(with final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_report_df): 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일어나 스터디해야지 업데이트: 안혜준 정리 - GPT-2의 학습 데이터와 용량은 B...</td>\n",
       "      <td>메일 내용은 LLaMa-1 모델의 특징과 성능 검토, 지속가능 교과목 25선 확인,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  일어나 스터디해야지 업데이트: 안혜준 정리 - GPT-2의 학습 데이터와 용량은 B...   \n",
       "\n",
       "                                              report  \n",
       "0  메일 내용은 LLaMa-1 모델의 특징과 성능 검토, 지속가능 교과목 25선 확인,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_report_df = pd.read_csv(GENERATED_REPORT_CSV)\n",
    "print(\"len(generated_report_df):\", len(generated_report_df))\n",
    "generated_report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "g-eval start with **gpt-4o-mini**\n",
      "\n",
      "=====================================================\n",
      "[G-EVAL] aspect=consistency, gpt_text=4\n",
      "[G-EVAL] aspect=coherence, gpt_text=Coherence: 2\n",
      "[G-EVAL] aspect=fluency, gpt_text=- Fluency (1-3): 2\n",
      "[G-EVAL] aspect=relevance, gpt_text=4\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"g-eval\"] = calculate_g_eval(\n",
    "    source_texts=generated_report_df[\"source\"].tolist(),\n",
    "    generated_texts=generated_report_df[\"report\"].tolist(),\n",
    "    eval_type=\"report\",\n",
    "    model_name=Config.config[\"summary\"][\"g_eval\"][\"openai_model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== REPORT Evaluation Results =====\n",
      "\n",
      "--- Report Sample 1 ---\n",
      "[G-EVAL] consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n",
      "\n",
      "===== Averages =====\n",
      "\n",
      "[G-EVAL Avg]\n",
      "  consistency=4.0000, coherence=2.0000, fluency=2.0000, relevance=4.0000\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(results, eval_type=\"report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
